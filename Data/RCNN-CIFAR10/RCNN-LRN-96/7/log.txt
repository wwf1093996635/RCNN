µÚ1²ã»»Îª0-iterµÄRCL
start training
validating val_loss:2.303806782 val_acc:0.069911859
epoch=1 train_loss:2.053057099 train_acc:0.205048077 validating val_loss:1.947107792 val_acc:0.246294071
epoch=2 train_loss:1.648004142 train_acc:0.374058494 validating val_loss:1.572541833 val_acc:0.416666667
epoch=3 train_loss:1.429267014 train_acc:0.471073718 validating val_loss:1.336034417 val_acc:0.525941506
epoch=4 train_loss:1.277204311 train_acc:0.533954327 validating val_loss:1.306115627 val_acc:0.542868590
epoch=5 train_loss:1.153128532 train_acc:0.587620192 validating val_loss:1.326127887 val_acc:0.541766827
epoch=6 train_loss:1.063798357 train_acc:0.623417468 validating val_loss:1.003634453 val_acc:0.648237179
epoch=7 train_loss:0.984053288 train_acc:0.651782853 validating val_loss:0.910004973 val_acc:0.678986378
epoch=8 train_loss:0.920837682 train_acc:0.675981571 validating val_loss:0.849723756 val_acc:0.706931090
epoch=9 train_loss:0.876677586 train_acc:0.690665064 validating val_loss:0.815735936 val_acc:0.718649840
epoch=10 train_loss:0.817733889 train_acc:0.712760417 validating val_loss:0.786189079 val_acc:0.727363782
epoch=11 train_loss:0.779947396 train_acc:0.725801282 validating val_loss:0.739028513 val_acc:0.748798077
epoch=12 train_loss:0.747536320 train_acc:0.735396635 validating val_loss:0.715166867 val_acc:0.756710737
epoch=13 train_loss:0.717097795 train_acc:0.745873397 validating val_loss:0.699162066 val_acc:0.759715545
epoch=14 train_loss:0.684223785 train_acc:0.761217949 validating val_loss:0.666385114 val_acc:0.769030449
epoch=15 train_loss:0.668375975 train_acc:0.766586538 validating val_loss:0.710189462 val_acc:0.759715545
epoch=16 train_loss:0.639969787 train_acc:0.777283654 validating val_loss:0.665035069 val_acc:0.772736378
epoch=17 train_loss:0.620386284 train_acc:0.783673878 validating val_loss:0.630100965 val_acc:0.783353365
epoch=18 train_loss:0.604240724 train_acc:0.789423077 validating val_loss:0.611269772 val_acc:0.793469551
epoch=19 train_loss:0.594430385 train_acc:0.795032051 validating val_loss:0.580675066 val_acc:0.798677885
epoch=20 train_loss:0.568540278 train_acc:0.800360577 validating val_loss:0.576286972 val_acc:0.805188301
epoch=21 train_loss:0.561048428 train_acc:0.804326923 validating val_loss:0.610715210 val_acc:0.792868590
epoch=22 train_loss:0.543758660 train_acc:0.810176282 validating val_loss:0.595737875 val_acc:0.797375801
epoch=23 train_loss:0.527908222 train_acc:0.815564904 validating val_loss:0.559572220 val_acc:0.806290064
epoch=24 train_loss:0.520177361 train_acc:0.816125801 validating val_loss:0.554357231 val_acc:0.809495192
epoch=25 train_loss:0.507066796 train_acc:0.821474359 validating val_loss:0.536807418 val_acc:0.817708333
epoch=26 train_loss:0.499175240 train_acc:0.826722756 validating val_loss:0.596102774 val_acc:0.798177083
epoch=27 train_loss:0.492458319 train_acc:0.828685897 validating val_loss:0.555318713 val_acc:0.812199519
epoch=28 train_loss:0.480258820 train_acc:0.833193109 validating val_loss:0.489171505 val_acc:0.833633814
epoch=29 train_loss:0.477064565 train_acc:0.833954327 validating val_loss:0.508858383 val_acc:0.826322115
epoch=30 train_loss:0.465517412 train_acc:0.836498397 validating val_loss:0.499672145 val_acc:0.835436699
epoch=31 train_loss:0.464916297 train_acc:0.836718750 validating val_loss:0.538072407 val_acc:0.817407853
epoch=32 train_loss:0.446758155 train_acc:0.844170673 validating val_loss:0.509022176 val_acc:0.832431891
epoch=33 train_loss:0.442462164 train_acc:0.844691506 validating val_loss:0.509287715 val_acc:0.829427083
epoch=34 train_loss:0.437121628 train_acc:0.847195513 validating val_loss:0.493393481 val_acc:0.834635417
epoch=35 train_loss:0.429255280 train_acc:0.849939904 validating val_loss:0.500080824 val_acc:0.831430288
epoch=36 train_loss:0.426248316 train_acc:0.849258814 validating val_loss:0.543462932 val_acc:0.821414263
epoch=37 train_loss:0.421880260 train_acc:0.851782853 validating val_loss:0.484563679 val_acc:0.840044071
epoch=38 train_loss:0.413359669 train_acc:0.856911058 validating val_loss:0.495047837 val_acc:0.835637019
epoch=39 train_loss:0.409657059 train_acc:0.857772436 validating val_loss:0.492640436 val_acc:0.838842147
epoch=40 train_loss:0.403613843 train_acc:0.858814103 validating val_loss:0.488993198 val_acc:0.839142628
epoch=41 train_loss:0.404067927 train_acc:0.858373397 validating val_loss:0.472314447 val_acc:0.843750000
epoch=42 train_loss:0.393109846 train_acc:0.860657051 validating val_loss:0.478959203 val_acc:0.841646635
epoch=43 train_loss:0.387571841 train_acc:0.865244391 validating val_loss:0.474033862 val_acc:0.844651442
epoch=44 train_loss:0.384533768 train_acc:0.865284455 validating val_loss:0.479338676 val_acc:0.843349359
epoch=45 train_loss:0.388449776 train_acc:0.862800481 validating val_loss:0.483717859 val_acc:0.839743590
epoch=46 train_loss:0.379677243 train_acc:0.864843750 validating val_loss:0.516402841 val_acc:0.831430288
epoch=47 train_loss:0.376477616 train_acc:0.866486378 validating val_loss:0.481015474 val_acc:0.841646635
epoch=48 train_loss:0.361912819 train_acc:0.873417468 validating val_loss:0.510381818 val_acc:0.831931090
epoch=49 train_loss:0.370465013 train_acc:0.870653045 validating val_loss:0.488197327 val_acc:0.837540064
epoch=50 train_loss:0.361941189 train_acc:0.873918269 validating val_loss:0.481947243 val_acc:0.838741987
epoch=51 train_loss:0.363815362 train_acc:0.871294071 validating val_loss:0.476547599 val_acc:0.844250801
epoch=52 train_loss:0.354252205 train_acc:0.876582532 validating val_loss:0.467334986 val_acc:0.848557692
epoch=53 train_loss:0.353552953 train_acc:0.875520833 validating val_loss:0.484370023 val_acc:0.839142628
epoch=54 train_loss:0.347688081 train_acc:0.877884615 validating val_loss:0.470943004 val_acc:0.844150641
epoch=55 train_loss:0.347353498 train_acc:0.879487179 validating val_loss:0.486003429 val_acc:0.842548077
epoch=56 train_loss:0.341612151 train_acc:0.878485577 validating val_loss:0.472505569 val_acc:0.845252404
epoch=57 train_loss:0.337631972 train_acc:0.881370192 validating val_loss:0.511614025 val_acc:0.840344551
epoch=58 train_loss:0.338702384 train_acc:0.881991186 validating val_loss:0.460251778 val_acc:0.852964744
epoch=59 train_loss:0.337432613 train_acc:0.880829327 validating val_loss:0.506041944 val_acc:0.837339744
epoch=60 train_loss:0.339635560 train_acc:0.879667468 validating val_loss:0.462849200 val_acc:0.854967949
epoch=61 train_loss:0.327015861 train_acc:0.883453526 validating val_loss:0.476116151 val_acc:0.845452724
epoch=62 train_loss:0.334876967 train_acc:0.882712340 validating val_loss:0.467619687 val_acc:0.844651442
epoch=63 
train_loss:0.329069025 train_acc:0.883934295 validating val_loss:0.478142977 val_acc:0.843048878
epoch=64 train_loss:0.329108067 train_acc:0.884014423 validating val_loss:0.465813339 val_acc:0.850160256
epoch=65 train_loss:0.331001921 train_acc:0.884294872 validating val_loss:0.457179874 val_acc:0.854366987
epoch=66 train_loss:0.321108334 train_acc:0.886598558 validating val_loss:0.484275788 val_acc:0.843950321
epoch=67 train_loss:0.324538481 train_acc:0.886237981 validating val_loss:0.494027615 val_acc:0.840745192
epoch=68 train_loss:0.317342918 train_acc:0.888000801 validating val_loss:0.486137599 val_acc:0.846654647
epoch=69 train_loss:0.320399438 train_acc:0.887540064 validating val_loss:0.462391138 val_acc:0.851061699
epoch=70 train_loss:0.317848183 train_acc:0.888221154 validating val_loss:0.466995001 val_acc:0.847556090
epoch=71 train_loss:0.319378733 train_acc:0.887620192 validating val_loss:0.488509595 val_acc:0.845953526
epoch=72 train_loss:0.314445613 train_acc:0.887680288 validating val_loss:0.471787870 val_acc:0.849258814
epoch=73 train_loss:0.314551227 train_acc:0.888201122 validating val_loss:0.496377856 val_acc:0.845152244
epoch=74 train_loss:0.310231491 train_acc:0.891887019 validating val_loss:0.480577677 val_acc:0.847756410
epoch=75 train_loss:0.313455479 train_acc:0.888902244 validating val_loss:0.486700743 val_acc:0.841045673
epoch=76 train_loss:0.304462266 train_acc:0.892287660 validating val_loss:0.491127908 val_acc:0.841646635
Epoch    76: reducing learning rate of group 0 to 1.0000e-03.
epoch=77 train_loss:0.238157314 train_acc:0.915685096 validating val_loss:0.442250490 val_acc:0.863080929
epoch=78 train_loss:0.217342390 train_acc:0.923677885 validating val_loss:0.457565516 val_acc:0.860376603
epoch=79 train_loss:0.209567298 train_acc:0.925701122 validating val_loss:0.451028526 val_acc:0.862680288
epoch=80 train_loss:0.202296340 train_acc:0.927764423 validating val_loss:0.457866520 val_acc:0.861478365
epoch=81 train_loss:0.202365823 train_acc:0.927383814 validating val_loss:0.451117486 val_acc:0.863581731
epoch=82 train_loss:0.194822201 train_acc:0.931109776 validating val_loss:0.465975851 val_acc:0.862680288
epoch=83 train_loss:0.194684776 train_acc:0.930749199 validating val_loss:0.456353843 val_acc:0.866085737
epoch=84 train_loss:0.191878959 train_acc:0.931290064 validating val_loss:0.459130764 val_acc:0.863481571
epoch=85 train_loss:0.187902272 train_acc:0.932491987 validating val_loss:0.455733716 val_acc:0.865584936
epoch=86 train_loss:0.187437497 train_acc:0.933213141 validating val_loss:0.463903964 val_acc:0.867087340
epoch=87 train_loss:0.183311952 train_acc:0.934595353 validating val_loss:0.461599171 val_acc:0.865084135
epoch=88 train_loss:0.181250767 train_acc:0.934254808 validating val_loss:0.469010979 val_acc:0.864282853
Epoch    88: reducing learning rate of group 0 to 1.0000e-04.
epoch=89 train_loss:0.175744946 train_acc:0.936738782 validating val_loss:0.465277910 val_acc:0.867387821
epoch=90 train_loss:0.174345456 train_acc:0.936658654 validating val_loss:0.467275769 val_acc:0.867187500
epoch=91 train_loss:0.177189781 train_acc:0.937019231 validating val_loss:0.462628484 val_acc:0.868289263
epoch=92 train_loss:0.171893980 train_acc:0.938461538 validating val_loss:0.463934630 val_acc:0.867287660
epoch=93 train_loss:0.171666276 train_acc:0.940244391 validating val_loss:0.463815153 val_acc:0.867287660
epoch=94 train_loss:0.174855132 train_acc:0.937139423 validating val_loss:0.466494590 val_acc:0.867588141
epoch=95 train_loss:0.171620615 train_acc:0.939002404 validating val_loss:0.464692384 val_acc:0.867287660
epoch=96 train_loss:0.172229819 train_acc:0.937479968 validating val_loss:0.465398073 val_acc:0.867588141
epoch=97 train_loss:0.172531386 train_acc:0.938401442 validating val_loss:0.467332661 val_acc:0.866786859
epoch=98 train_loss:0.174869624 train_acc:0.936838942 validating val_loss:0.463774562 val_acc:0.867387821
epoch=99 train_loss:0.169271756 train_acc:0.939483173 validating val_loss:0.465459377 val_acc:0.867387821
