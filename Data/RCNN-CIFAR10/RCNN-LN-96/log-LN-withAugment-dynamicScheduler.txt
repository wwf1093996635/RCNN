nohup: ignoring input
1.0.1.post2
cuda is available
start training
validating val_loss:2.6213 val_acc:0.0923
epoch=1 train_loss:1.9346 train_acc:0.2831 validating val_loss:1.7209 val_acc:0.3093
epoch=2 train_loss:1.4271 train_acc:0.4784 validating val_loss:1.3947 val_acc:0.5353
epoch=3 train_loss:1.2198 train_acc:0.5655 validating val_loss:1.2916 val_acc:0.5565
epoch=4 train_loss:1.0886 train_acc:0.6165 validating val_loss:1.1629 val_acc:0.6499
epoch=5 train_loss:0.9972 train_acc:0.6521 validating val_loss:1.0914 val_acc:0.6704
epoch=6 train_loss:0.9259 train_acc:0.6800 validating val_loss:0.9319 val_acc:0.7296
epoch=7 train_loss:0.8585 train_acc:0.7009 validating val_loss:0.8562 val_acc:0.7511
epoch=8 train_loss:0.8150 train_acc:0.7206 validating val_loss:0.8473 val_acc:0.7517
epoch=9 train_loss:0.7678 train_acc:0.7354 validating val_loss:0.8038 val_acc:0.7813
epoch=10 train_loss:0.7347 train_acc:0.7464 validating val_loss:0.8000 val_acc:0.7885
epoch=11 train_loss:0.7065 train_acc:0.7576 validating val_loss:0.7456 val_acc:0.8063
epoch=12 train_loss:0.6806 train_acc:0.7644 validating val_loss:0.7221 val_acc:0.7993
epoch=13 train_loss:0.6481 train_acc:0.7782 validating val_loss:0.7116 val_acc:0.7924
epoch=14 train_loss:0.6302 train_acc:0.7837 validating val_loss:0.6948 val_acc:0.8053
epoch=15 train_loss:0.6118 train_acc:0.7914 validating val_loss:0.6566 val_acc:0.8073
epoch=16 train_loss:0.5922 train_acc:0.7985 validating val_loss:0.6695 val_acc:0.8255
epoch=17 train_loss:0.5776 train_acc:0.8029 validating val_loss:0.6223 val_acc:0.8349
epoch=18 train_loss:0.5625 train_acc:0.8072 validating val_loss:0.6360 val_acc:0.8243
epoch=19 train_loss:0.5542 train_acc:0.8108 validating val_loss:0.5878 val_acc:0.8408
epoch=20 train_loss:0.5399 train_acc:0.8150 validating val_loss:0.6071 val_acc:0.8181
epoch=21 train_loss:0.5237 train_acc:0.8196 validating val_loss:0.5997 val_acc:0.8307
epoch=22 train_loss:0.5138 train_acc:0.8241 validating val_loss:0.5751 val_acc:0.8411
epoch=23 train_loss:0.5023 train_acc:0.8266 validating val_loss:0.5575 val_acc:0.8371
epoch=24 train_loss:0.4933 train_acc:0.8299 validating val_loss:0.5538 val_acc:0.8526
epoch=25 train_loss:0.4848 train_acc:0.8331 validating val_loss:0.5190 val_acc:0.8503
epoch=26 train_loss:0.4715 train_acc:0.8394 validating val_loss:0.5329 val_acc:0.8479
epoch=27 train_loss:0.4704 train_acc:0.8395 validating val_loss:0.5235 val_acc:0.8528
epoch=28 train_loss:0.4602 train_acc:0.8435 validating val_loss:0.4867 val_acc:0.8602
epoch=29 train_loss:0.4503 train_acc:0.8440 validating val_loss:0.5165 val_acc:0.8536
epoch=30 train_loss:0.4478 train_acc:0.8456 validating val_loss:0.4975 val_acc:0.8582
epoch=31 train_loss:0.4366 train_acc:0.8500 validating val_loss:0.4884 val_acc:0.8579
epoch=32 train_loss:0.4341 train_acc:0.8512 validating val_loss:0.5181 val_acc:0.8545
epoch=33 train_loss:0.4238 train_acc:0.8551 validating val_loss:0.4760 val_acc:0.8705
epoch=34 train_loss:0.4189 train_acc:0.8575 validating val_loss:0.4866 val_acc:0.8497
epoch=35 train_loss:0.4109 train_acc:0.8583 validating val_loss:0.4754 val_acc:0.8583
epoch=36 train_loss:0.4041 train_acc:0.8625 validating val_loss:0.4653 val_acc:0.8671
epoch=37 train_loss:0.4023 train_acc:0.8640 validating val_loss:0.4728 val_acc:0.8700
epoch=38 train_loss:0.3983 train_acc:0.8644 validating val_loss:0.4564 val_acc:0.8736
epoch=39 train_loss:0.3902 train_acc:0.8675 validating val_loss:0.4548 val_acc:0.8701
epoch=40 train_loss:0.3814 train_acc:0.8691 validating val_loss:0.4537 val_acc:0.8714
epoch=41 train_loss:0.3828 train_acc:0.8682 validating val_loss:0.4422 val_acc:0.8695
epoch=42 train_loss:0.3733 train_acc:0.8736 validating val_loss:0.4457 val_acc:0.8743
epoch=43 train_loss:0.3735 train_acc:0.8706 validating val_loss:0.4434 val_acc:0.8743
epoch=44 train_loss:0.3678 train_acc:0.8747 validating val_loss:0.4261 val_acc:0.8789
epoch=45 train_loss:0.3594 train_acc:0.8752 validating val_loss:0.4255 val_acc:0.8744
epoch=46 train_loss:0.3607 train_acc:0.8756 validating val_loss:0.4210 val_acc:0.8765
epoch=47 train_loss:0.3530 train_acc:0.8806 validating val_loss:0.4462 val_acc:0.8754
epoch=48 train_loss:0.3498 train_acc:0.8807 validating val_loss:0.4164 val_acc:0.8760
epoch=49 train_loss:0.3441 train_acc:0.8808 validating val_loss:0.4098 val_acc:0.8786
epoch=50 train_loss:0.3397 train_acc:0.8844 validating val_loss:0.4217 val_acc:0.8773
epoch=51 train_loss:0.3382 train_acc:0.8845 validating val_loss:0.4066 val_acc:0.8853
epoch=52 train_loss:0.3369 train_acc:0.8847 validating val_loss:0.4053 val_acc:0.8814
epoch=53 train_loss:0.3337 train_acc:0.8836 validating val_loss:0.4210 val_acc:0.8776
epoch=54 train_loss:0.3301 train_acc:0.8867 validating val_loss:0.3985 val_acc:0.8814
epoch=55 train_loss:0.3224 train_acc:0.8884 validating val_loss:0.4133 val_acc:0.8703
epoch=56 train_loss:0.3228 train_acc:0.8896 validating val_loss:0.4024 val_acc:0.8817
epoch=57 train_loss:0.3191 train_acc:0.8898 validating val_loss:0.3880 val_acc:0.8844
epoch=58 train_loss:0.3166 train_acc:0.8924 validating val_loss:0.3854 val_acc:0.8860
epoch=59 train_loss:0.3083 train_acc:0.8943 validating val_loss:0.3949 val_acc:0.8838
epoch=60 train_loss:0.3097 train_acc:0.8940 validating val_loss:0.3850 val_acc:0.8868
epoch=61 train_loss:0.3079 train_acc:0.8945 validating val_loss:0.3833 val_acc:0.8857
epoch=62 train_loss:0.3006 train_acc:0.8961 validating val_loss:0.3847 val_acc:0.8868
epoch=63 train_loss:0.3015 train_acc:0.8963 validating val_loss:0.3655 val_acc:0.8919
epoch=64 train_loss:0.3017 train_acc:0.8948 validating val_loss:0.3775 val_acc:0.8885
epoch=65 train_loss:0.2962 train_acc:0.8986 validating val_loss:0.3851 val_acc:0.8825
epoch=66 train_loss:0.2894 train_acc:0.9005 validating val_loss:0.3682 val_acc:0.8837
epoch=67 train_loss:0.2846 train_acc:0.9017 validating val_loss:0.3811 val_acc:0.8855
epoch=68 train_loss:0.2884 train_acc:0.9011 validating val_loss:0.3836 val_acc:0.8892
epoch=69 train_loss:0.2834 train_acc:0.9031 validating val_loss:0.3828 val_acc:0.8810
epoch=70 train_loss:0.2832 train_acc:0.9032 validating val_loss:0.3777 val_acc:0.8858
epoch=71 train_loss:0.2796 train_acc:0.9032 validating val_loss:0.3754 val_acc:0.8794
epoch=72 train_loss:0.2794 train_acc:0.9037 validating val_loss:0.3785 val_acc:0.8829
epoch=73 train_loss:0.2779 train_acc:0.9035 validating val_loss:0.3659 val_acc:0.8896
epoch=74 train_loss:0.2727 train_acc:0.9060 validating val_loss:0.3602 val_acc:0.8904
epoch=75 train_loss:0.2696 train_acc:0.9072 validating val_loss:0.3728 val_acc:0.8862
epoch=76 train_loss:0.2700 train_acc:0.9067 validating val_loss:0.3707 val_acc:0.8896
epoch=77 train_loss:0.2658 train_acc:0.9085 validating val_loss:0.3671 val_acc:0.8866
epoch=78 train_loss:0.2696 train_acc:0.9072 validating val_loss:0.3754 val_acc:0.8806
epoch=79 train_loss:0.2618 train_acc:0.9108 validating val_loss:0.3719 val_acc:0.8818
epoch=80 train_loss:0.2604 train_acc:0.9108 validating val_loss:0.3549 val_acc:0.8895
epoch=81 train_loss:0.2560 train_acc:0.9121 validating val_loss:0.3501 val_acc:0.8941
epoch=82 train_loss:0.2557 train_acc:0.9113 validating val_loss:0.3543 val_acc:0.8889
epoch=83 train_loss:0.2572 train_acc:0.9120 validating val_loss:0.3501 val_acc:0.8886
epoch=84 train_loss:0.2545 train_acc:0.9132 validating val_loss:0.3725 val_acc:0.8911
epoch=85 train_loss:0.2546 train_acc:0.9112 validating val_loss:0.3513 val_acc:0.8896
epoch=86 train_loss:0.2522 train_acc:0.9134 validating val_loss:0.3737 val_acc:0.8806
epoch=87 train_loss:0.2454 train_acc:0.9141 validating val_loss:0.3434 val_acc:0.8905
epoch=88 train_loss:0.2513 train_acc:0.9142 validating val_loss:0.3667 val_acc:0.8892
epoch=89 train_loss:0.2469 train_acc:0.9150 validating val_loss:0.3528 val_acc:0.8892
epoch=90 train_loss:0.2451 train_acc:0.9158 validating val_loss:0.3530 val_acc:0.8899
epoch=91 train_loss:0.2351 train_acc:0.9201 validating val_loss:0.3351 val_acc:0.8941
epoch=92 train_loss:0.2441 train_acc:0.9158 validating val_loss:0.3455 val_acc:0.8885
epoch=93 train_loss:0.2357 train_acc:0.9194 validating val_loss:0.3399 val_acc:0.8938
epoch=94 train_loss:0.2351 train_acc:0.9199 validating val_loss:0.3436 val_acc:0.8881
epoch=95 train_loss:0.2359 train_acc:0.9193 validating val_loss:0.3447 val_acc:0.8892
epoch=96 train_loss:0.2374 train_acc:0.9174 validating val_loss:0.3472 val_acc:0.8923
epoch=97 train_loss:0.2303 train_acc:0.9206 validating val_loss:0.3500 val_acc:0.8878
epoch=98 train_loss:0.2346 train_acc:0.9200 validating val_loss:0.3554 val_acc:0.8875
epoch=99 train_loss:0.2295 train_acc:0.9212 validating val_loss:0.3482 val_acc:0.8933
epoch=100 train_loss:0.2236 train_acc:0.9219 validating val_loss:0.3391 val_acc:0.8934
epoch=101 train_loss:0.2300 train_acc:0.9199 validating val_loss:0.3465 val_acc:0.8895
epoch=102 train_loss:0.2263 train_acc:0.9222 validating val_loss:0.3454 val_acc:0.8906
Epoch   102: reducing learning rate of group 0 to 1.0000e-03.
epoch=103 train_loss:0.1786 train_acc:0.9374 validating val_loss:0.3026 val_acc:0.9009
epoch=104 train_loss:0.1698 train_acc:0.9404 validating val_loss:0.2940 val_acc:0.9037
epoch=105 train_loss:0.1628 train_acc:0.9441 validating val_loss:0.2929 val_acc:0.9048
epoch=106 train_loss:0.1592 train_acc:0.9451 validating val_loss:0.2942 val_acc:0.9034
epoch=107 train_loss:0.1555 train_acc:0.9456 validating val_loss:0.2903 val_acc:0.9035
epoch=108 train_loss:0.1535 train_acc:0.9478 validating val_loss:0.2876 val_acc:0.9050
epoch=109 train_loss:0.1507 train_acc:0.9480 validating val_loss:0.2857 val_acc:0.9033
epoch=110 train_loss:0.1492 train_acc:0.9490 validating val_loss:0.2867 val_acc:0.9048
epoch=111 train_loss:0.1463 train_acc:0.9502 validating val_loss:0.2882 val_acc:0.9043
epoch=112 train_loss:0.1457 train_acc:0.9492 validating val_loss:0.2868 val_acc:0.9031
epoch=113 train_loss:0.1434 train_acc:0.9516 validating val_loss:0.2882 val_acc:0.9033
epoch=114 train_loss:0.1441 train_acc:0.9498 validating val_loss:0.2836 val_acc:0.9044
epoch=115 train_loss:0.1392 train_acc:0.9521 validating val_loss:0.2817 val_acc:0.9056
epoch=116 train_loss:0.1422 train_acc:0.9512 validating val_loss:0.2845 val_acc:0.9048
epoch=117 train_loss:0.1426 train_acc:0.9505 validating val_loss:0.2844 val_acc:0.9043
epoch=118 train_loss:0.1410 train_acc:0.9506 validating val_loss:0.2824 val_acc:0.9048
epoch=119 train_loss:0.1384 train_acc:0.9520 validating val_loss:0.2832 val_acc:0.9052
epoch=120 train_loss:0.1389 train_acc:0.9528 validating val_loss:0.2850 val_acc:0.9044
epoch=121 train_loss:0.1357 train_acc:0.9536 validating val_loss:0.2833 val_acc:0.9046
epoch=122 train_loss:0.1320 train_acc:0.9550 validating val_loss:0.2813 val_acc:0.9048
epoch=123 train_loss:0.1353 train_acc:0.9536 validating val_loss:0.2807 val_acc:0.9047
epoch=124 train_loss:0.1343 train_acc:0.9533 validating val_loss:0.2814 val_acc:0.9063
epoch=125 train_loss:0.1355 train_acc:0.9528 validating val_loss:0.2868 val_acc:0.9030
epoch=126 train_loss:0.1329 train_acc:0.9540 validating val_loss:0.2817 val_acc:0.9066
epoch=127 train_loss:0.1296 train_acc:0.9547 validating val_loss:0.2806 val_acc:0.9055
epoch=128 train_loss:0.1302 train_acc:0.9550 validating val_loss:0.2817 val_acc:0.9053
epoch=129 train_loss:0.1293 train_acc:0.9558 validating val_loss:0.2836 val_acc:0.9031
epoch=130 train_loss:0.1311 train_acc:0.9554 validating val_loss:0.2803 val_acc:0.9071
epoch=131 train_loss:0.1294 train_acc:0.9556 validating val_loss:0.2837 val_acc:0.9025
epoch=132 train_loss:0.1257 train_acc:0.9559 validating val_loss:0.2837 val_acc:0.9055
epoch=133 train_loss:0.1343 train_acc:0.9529 validating val_loss:0.2792 val_acc:0.9060
epoch=134 train_loss:0.1325 train_acc:0.9542 validating val_loss:0.2824 val_acc:0.9034
epoch=135 train_loss:0.1270 train_acc:0.9561 validating val_loss:0.2796 val_acc:0.9060
epoch=136 train_loss:0.1293 train_acc:0.9560 validating val_loss:0.2807 val_acc:0.9038
epoch=137 train_loss:0.1283 train_acc:0.9555 validating val_loss:0.2776 val_acc:0.9056
epoch=138 train_loss:0.1240 train_acc:0.9564 validating val_loss:0.2767 val_acc:0.9068
epoch=139 train_loss:0.1257 train_acc:0.9573 validating val_loss:0.2795 val_acc:0.9043
epoch=140 train_loss:0.1248 train_acc:0.9580 validating val_loss:0.2780 val_acc:0.9054
epoch=141 train_loss:0.1255 train_acc:0.9559 validating val_loss:0.2811 val_acc:0.9055
epoch=142 train_loss:0.1242 train_acc:0.9573 validating val_loss:0.2796 val_acc:0.9075
epoch=143 train_loss:0.1249 train_acc:0.9571 validating val_loss:0.2793 val_acc:0.9062
epoch=144 train_loss:0.1236 train_acc:0.9567 validating val_loss:0.2769 val_acc:0.9072
epoch=145 train_loss:0.1225 train_acc:0.9577 validating val_loss:0.2795 val_acc:0.9044
epoch=146 train_loss:0.1215 train_acc:0.9572 validating val_loss:0.2794 val_acc:0.9054
epoch=147 train_loss:0.1201 train_acc:0.9580 validating val_loss:0.2787 val_acc:0.9070
epoch=148 train_loss:0.1251 train_acc:0.9578 validating val_loss:0.2818 val_acc:0.9027
epoch=149 train_loss:0.1206 train_acc:0.9580 validating val_loss:0.2789 val_acc:0.9055
Epoch   149: reducing learning rate of group 0 to 1.0000e-04.
epoch=150 train_loss:0.1183 train_acc:0.9592 validating val_loss:0.2763 val_acc:0.9066
epoch=151 train_loss:0.1138 train_acc:0.9611 validating val_loss:0.2752 val_acc:0.9071
epoch=152 train_loss:0.1153 train_acc:0.9596 validating val_loss:0.2743 val_acc:0.9072
epoch=153 train_loss:0.1149 train_acc:0.9609 validating val_loss:0.2741 val_acc:0.9062
epoch=154 train_loss:0.1209 train_acc:0.9575 validating val_loss:0.2766 val_acc:0.9069
epoch=155 train_loss:0.1142 train_acc:0.9599 validating val_loss:0.2743 val_acc:0.9059
epoch=156 train_loss:0.1139 train_acc:0.9611 validating val_loss:0.2761 val_acc:0.9065
epoch=157 train_loss:0.1129 train_acc:0.9619 validating val_loss:0.2756 val_acc:0.9050
epoch=158 train_loss:0.1131 train_acc:0.9608 validating val_loss:0.2750 val_acc:0.9059
epoch=159 train_loss:0.1134 train_acc:0.9612 validating val_loss:0.2753 val_acc:0.9060
epoch=160 train_loss:0.1156 train_acc:0.9603 validating val_loss:0.2739 val_acc:0.9069
epoch=161 train_loss:0.1142 train_acc:0.9599 validating val_loss:0.2741 val_acc:0.9070
epoch=162 train_loss:0.1147 train_acc:0.9600 validating val_loss:0.2733 val_acc:0.9071
epoch=163 train_loss:0.1160 train_acc:0.9599 validating val_loss:0.2746 val_acc:0.9065
epoch=164 train_loss:0.1110 train_acc:0.9615 validating val_loss:0.2758 val_acc:0.9068
epoch=165 train_loss:0.1180 train_acc:0.9605 validating val_loss:0.2745 val_acc:0.9070
epoch=166 train_loss:0.1130 train_acc:0.9606 validating val_loss:0.2769 val_acc:0.9068
epoch=167 train_loss:0.1117 train_acc:0.9618 validating val_loss:0.2737 val_acc:0.9067
epoch=168 train_loss:0.1127 train_acc:0.9606 validating val_loss:0.2744 val_acc:0.9066
epoch=169 train_loss:0.1142 train_acc:0.9610 validating val_loss:0.2733 val_acc:0.9070
epoch=170 train_loss:0.1097 train_acc:0.9615 validating val_loss:0.2734 val_acc:0.9069
epoch=171 train_loss:0.1106 train_acc:0.9619 validating val_loss:0.2719 val_acc:0.9065
epoch=172 train_loss:0.1136 train_acc:0.9608 validating val_loss:0.2747 val_acc:0.9066
epoch=173 train_loss:0.1131 train_acc:0.9612 validating val_loss:0.2736 val_acc:0.9070
epoch=174 train_loss:0.1162 train_acc:0.9604 validating val_loss:0.2733 val_acc:0.9072
epoch=175 train_loss:0.1114 train_acc:0.9615 validating val_loss:0.2731 val_acc:0.9070
epoch=176 train_loss:0.1139 train_acc:0.9607 validating val_loss:0.2741 val_acc:0.9072
epoch=177 train_loss:0.1147 train_acc:0.9603 validating val_loss:0.2760 val_acc:0.9066
epoch=178 train_loss:0.1097 train_acc:0.9612 validating val_loss:0.2732 val_acc:0.9066
epoch=179 train_loss:0.1131 train_acc:0.9611 validating val_loss:0.2732 val_acc:0.9068
epoch=180 train_loss:0.1126 train_acc:0.9613 validating val_loss:0.2746 val_acc:0.9066
epoch=181 train_loss:0.1129 train_acc:0.9606 validating val_loss:0.2735 val_acc:0.9065
epoch=182 train_loss:0.1106 train_acc:0.9615 validating val_loss:0.2728 val_acc:0.9063
Epoch   182: reducing learning rate of group 0 to 1.0000e-05.
epoch=183 train_loss:0.1160 train_acc:0.9596 validating val_loss:0.2735 val_acc:0.9071
epoch=184 train_loss:0.1128 train_acc:0.9613 validating val_loss:0.2749 val_acc:0.9067
epoch=185 train_loss:0.1134 train_acc:0.9606 validating val_loss:0.2737 val_acc:0.9071
epoch=186 train_loss:0.1079 train_acc:0.9627 validating val_loss:0.2745 val_acc:0.9070
epoch=187 train_loss:0.1104 train_acc:0.9625 validating val_loss:0.2743 val_acc:0.9068
epoch=188 train_loss:0.1120 train_acc:0.9603 validating val_loss:0.2729 val_acc:0.9071
epoch=189 train_loss:0.1132 train_acc:0.9618 validating val_loss:0.2753 val_acc:0.9076
epoch=190 train_loss:0.1142 train_acc:0.9614 validating val_loss:0.2738 val_acc:0.9069
epoch=191 train_loss:0.1143 train_acc:0.9608 validating val_loss:0.2738 val_acc:0.9076
epoch=192 train_loss:0.1135 train_acc:0.9616 validating val_loss:0.2733 val_acc:0.9076
epoch=193 train_loss:0.1148 train_acc:0.9609 validating val_loss:0.2735 val_acc:0.9059
Epoch   193: reducing learning rate of group 0 to 1.0000e-06.
epoch=194 train_loss:0.1121 train_acc:0.9616 validating val_loss:0.2742 val_acc:0.9064
epoch=195 train_loss:0.1126 train_acc:0.9602 validating val_loss:0.2749 val_acc:0.9066
epoch=196 train_loss:0.1088 train_acc:0.9617 validating val_loss:0.2728 val_acc:0.9067
epoch=197 train_loss:0.1139 train_acc:0.9602 validating val_loss:0.2745 val_acc:0.9067
epoch=198 train_loss:0.1092 train_acc:0.9628 validating val_loss:0.2742 val_acc:0.9068
epoch=199 train_loss:0.1117 train_acc:0.9624 validating val_loss:0.2735 val_acc:0.9071
Finished Training
