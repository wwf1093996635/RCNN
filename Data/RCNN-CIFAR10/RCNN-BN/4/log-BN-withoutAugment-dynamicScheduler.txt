nohup: ignoring input
1.0.1.post2
cuda is available
start training
validating val_loss:2.3049 val_acc:0.1000
epoch=1 train_loss:1.7515 train_acc:0.3497 validating val_loss:5.7102 val_acc:0.1546
epoch=2 train_loss:1.3728 train_acc:0.5033 validating val_loss:32413793.7659 val_acc:0.1410
epoch=3 train_loss:1.1824 train_acc:0.5830 validating val_loss:611511.7368 val_acc:0.2248
epoch=4 train_loss:1.0671 train_acc:0.6283 validating val_loss:435447.8505 val_acc:0.2465
epoch=5 train_loss:0.9782 train_acc:0.6655 validating val_loss:4128624.5738 val_acc:0.2959
epoch=6 train_loss:0.9004 train_acc:0.6938 validating val_loss:3982.3545 val_acc:0.2598
epoch=7 train_loss:0.8301 train_acc:0.7194 validating val_loss:1275.5757 val_acc:0.3852
epoch=8 train_loss:0.7621 train_acc:0.7459 validating val_loss:990.7333 val_acc:0.3815
epoch=9 train_loss:0.7091 train_acc:0.7663 validating val_loss:1763.4952 val_acc:0.3775
epoch=10 train_loss:0.6687 train_acc:0.7813 validating val_loss:1.9291 val_acc:0.5382
epoch=11 train_loss:0.6297 train_acc:0.7926 validating val_loss:2.0234 val_acc:0.6074
epoch=12 train_loss:0.5865 train_acc:0.8099 validating val_loss:1.8602 val_acc:0.5813
epoch=13 train_loss:0.5730 train_acc:0.8122 validating val_loss:16903.2420 val_acc:0.1187
epoch=14 train_loss:0.5490 train_acc:0.8215 validating val_loss:1.5437 val_acc:0.6154
epoch=15 train_loss:0.5320 train_acc:0.8255 validating val_loss:1.5185 val_acc:0.6349
epoch=16 train_loss:0.5061 train_acc:0.8364 validating val_loss:2.4727 val_acc:0.5721
epoch=17 train_loss:0.4867 train_acc:0.8437 validating val_loss:1.7569 val_acc:0.6556
epoch=18 train_loss:0.4774 train_acc:0.8440 validating val_loss:2.0566 val_acc:0.6063
epoch=19 train_loss:0.4575 train_acc:0.8531 validating val_loss:2.0112 val_acc:0.5863
epoch=20 train_loss:0.4477 train_acc:0.8548 validating val_loss:1.8665 val_acc:0.6109
epoch=21 train_loss:0.4410 train_acc:0.8582 validating val_loss:1.6610 val_acc:0.6267
epoch=22 train_loss:0.4242 train_acc:0.8629 validating val_loss:2.0411 val_acc:0.6205
epoch=23 train_loss:0.4232 train_acc:0.8638 validating val_loss:1.9702 val_acc:0.6058
epoch=24 train_loss:0.4001 train_acc:0.8716 validating val_loss:1.5551 val_acc:0.6710
epoch=25 train_loss:0.3994 train_acc:0.8707 validating val_loss:1.4968 val_acc:0.6706
epoch=26 train_loss:0.3896 train_acc:0.8747 validating val_loss:1.2061 val_acc:0.7162
epoch=27 train_loss:0.3775 train_acc:0.8786 validating val_loss:1.6959 val_acc:0.6493
epoch=28 train_loss:0.3712 train_acc:0.8806 validating val_loss:1.2180 val_acc:0.7138
epoch=29 train_loss:0.3613 train_acc:0.8842 validating val_loss:1.2937 val_acc:0.7149
epoch=30 train_loss:0.3612 train_acc:0.8838 validating val_loss:2.2243 val_acc:0.6169
epoch=31 train_loss:0.3744 train_acc:0.8799 validating val_loss:1.5277 val_acc:0.6655
epoch=32 train_loss:0.3572 train_acc:0.8855 validating val_loss:1.8933 val_acc:0.6715
epoch=33 train_loss:0.3501 train_acc:0.8883 validating val_loss:1.6283 val_acc:0.6678
epoch=34 train_loss:0.3523 train_acc:0.8865 validating val_loss:2.0256 val_acc:0.6110
epoch=35 train_loss:0.3366 train_acc:0.8920 validating val_loss:1.9653 val_acc:0.6293
epoch=36 train_loss:0.3396 train_acc:0.8913 validating val_loss:1.6854 val_acc:0.6459
epoch=37 train_loss:0.3374 train_acc:0.8910 validating val_loss:2.4034 val_acc:0.5960
Epoch    37: reducing learning rate of group 0 to 1.0000e-02.
epoch=38 train_loss:0.1663 train_acc:0.9465 validating val_loss:2.0621 val_acc:0.6865
epoch=39 train_loss:0.1041 train_acc:0.9666 validating val_loss:2.3463 val_acc:0.6870
epoch=40 train_loss:0.0787 train_acc:0.9746 validating val_loss:2.4659 val_acc:0.6887
epoch=41 train_loss:0.0650 train_acc:0.9801 validating val_loss:3.0656 val_acc:0.6720
epoch=42 train_loss:0.0513 train_acc:0.9843 validating val_loss:2.7411 val_acc:0.6901
epoch=43 train_loss:0.0429 train_acc:0.9869 validating val_loss:3.2281 val_acc:0.6712
epoch=44 train_loss:0.0381 train_acc:0.9881 validating val_loss:3.1043 val_acc:0.6798
epoch=45 train_loss:0.0314 train_acc:0.9905 validating val_loss:3.0489 val_acc:0.6836
epoch=46 train_loss:0.0258 train_acc:0.9921 validating val_loss:3.3293 val_acc:0.6835
epoch=47 train_loss:0.0217 train_acc:0.9935 validating val_loss:3.5606 val_acc:0.6799
epoch=48 train_loss:0.0197 train_acc:0.9940 validating val_loss:3.8837 val_acc:0.6711
Epoch    48: reducing learning rate of group 0 to 1.0000e-03.
epoch=49 train_loss:0.0155 train_acc:0.9957 validating val_loss:3.9647 val_acc:0.6737
epoch=50 train_loss:0.0136 train_acc:0.9963 validating val_loss:3.8427 val_acc:0.6729
epoch=51 train_loss:0.0128 train_acc:0.9967 validating val_loss:3.9254 val_acc:0.6746
epoch=52 train_loss:0.0125 train_acc:0.9965 validating val_loss:4.0425 val_acc:0.6688
epoch=53 train_loss:0.0103 train_acc:0.9974 validating val_loss:3.8221 val_acc:0.6748
epoch=54 train_loss:0.0113 train_acc:0.9973 validating val_loss:3.9015 val_acc:0.6746
epoch=55 train_loss:0.0109 train_acc:0.9972 validating val_loss:3.8747 val_acc:0.6773
epoch=56 train_loss:0.0109 train_acc:0.9973 validating val_loss:3.7038 val_acc:0.6817
epoch=57 train_loss:0.0104 train_acc:0.9973 validating val_loss:4.1144 val_acc:0.6716
epoch=58 train_loss:0.0101 train_acc:0.9977 validating val_loss:3.4963 val_acc:0.6923
epoch=59 train_loss:0.0097 train_acc:0.9977 validating val_loss:3.8777 val_acc:0.6785
Epoch    59: reducing learning rate of group 0 to 1.0000e-04.
epoch=60 train_loss:0.0098 train_acc:0.9976 validating val_loss:4.0589 val_acc:0.6767
epoch=61 train_loss:0.0095 train_acc:0.9978 validating val_loss:3.7781 val_acc:0.6862
epoch=62 train_loss:0.0089 train_acc:0.9979 validating val_loss:3.7539 val_acc:0.6816
epoch=63 train_loss:0.0090 train_acc:0.9978 validating val_loss:3.9783 val_acc:0.6769
epoch=64 train_loss:0.0101 train_acc:0.9974 validating val_loss:4.2484 val_acc:0.6700
epoch=65 train_loss:0.0093 train_acc:0.9979 validating val_loss:4.2498 val_acc:0.6763
epoch=66 train_loss:0.0095 train_acc:0.9979 validating val_loss:3.9240 val_acc:0.6732
epoch=67 train_loss:0.0101 train_acc:0.9980 validating val_loss:4.2996 val_acc:0.6781
epoch=68 train_loss:0.0088 train_acc:0.9981 validating val_loss:3.9406 val_acc:0.6734
epoch=69 train_loss:0.0099 train_acc:0.9975 validating val_loss:4.0033 val_acc:0.6789
epoch=70 train_loss:0.0085 train_acc:0.9979 validating val_loss:4.2483 val_acc:0.6697
Epoch    70: reducing learning rate of group 0 to 1.0000e-05.
epoch=71 train_loss:0.0085 train_acc:0.9981 validating val_loss:4.1637 val_acc:0.6733
epoch=72 train_loss:0.0095 train_acc:0.9977 validating val_loss:3.5649 val_acc:0.6886
epoch=73 train_loss:0.0089 train_acc:0.9978 validating val_loss:3.9813 val_acc:0.6798
epoch=74 train_loss:0.0090 train_acc:0.9980 validating val_loss:3.8686 val_acc:0.6766
epoch=75 train_loss:0.0094 train_acc:0.9978 validating val_loss:4.1343 val_acc:0.6745
epoch=76 train_loss:0.0088 train_acc:0.9978 validating val_loss:3.6390 val_acc:0.6872
epoch=77 train_loss:0.0096 train_acc:0.9977 validating val_loss:3.9336 val_acc:0.6767
epoch=78 train_loss:0.0091 train_acc:0.9978 validating val_loss:4.2361 val_acc:0.6746
epoch=79 train_loss:0.0091 train_acc:0.9977 validating val_loss:4.0967 val_acc:0.6781
epoch=80 train_loss:0.0084 train_acc:0.9980 validating val_loss:4.1770 val_acc:0.6764
epoch=81 train_loss:0.0090 train_acc:0.9979 validating val_loss:3.8737 val_acc:0.6785
Epoch    81: reducing learning rate of group 0 to 1.0000e-06.
epoch=82 train_loss:0.0094 train_acc:0.9976 validating val_loss:4.0778 val_acc:0.6777
epoch=83 train_loss:0.0086 train_acc:0.9979 validating val_loss:4.2470 val_acc:0.6650
epoch=84 train_loss:0.0097 train_acc:0.9976 validating val_loss:4.3340 val_acc:0.6736
epoch=85 train_loss:0.0086 train_acc:0.9981 validating val_loss:3.6750 val_acc:0.6876
epoch=86 train_loss:0.0095 train_acc:0.9981 validating val_loss:3.9652 val_acc:0.6838
epoch=87 train_loss:0.0090 train_acc:0.9980 validating val_loss:4.3127 val_acc:0.6736
epoch=88 train_loss:0.0092 train_acc:0.9978 validating val_loss:3.9493 val_acc:0.6845
epoch=89 train_loss:0.0100 train_acc:0.9979 validating val_loss:4.1578 val_acc:0.6699
epoch=90 train_loss:0.0119 train_acc:0.9980 validating val_loss:4.6010 val_acc:0.6623
epoch=91 train_loss:0.0093 train_acc:0.9978 validating val_loss:3.8844 val_acc:0.6759
epoch=92 train_loss:0.0093 train_acc:0.9976 validating val_loss:4.0242 val_acc:0.6693
Epoch    92: reducing learning rate of group 0 to 1.0000e-07.
epoch=93 train_loss:0.0085 train_acc:0.9981 validating val_loss:3.8827 val_acc:0.6815
epoch=94 train_loss:0.0090 train_acc:0.9979 validating val_loss:3.8159 val_acc:0.6787
epoch=95 train_loss:0.0087 train_acc:0.9978 validating val_loss:4.1044 val_acc:0.6628
epoch=96 train_loss:0.0088 train_acc:0.9981 validating val_loss:3.7082 val_acc:0.6889
epoch=97 train_loss:0.0082 train_acc:0.9980 validating val_loss:3.6589 val_acc:0.6870
epoch=98 train_loss:0.0095 train_acc:0.9980 validating val_loss:3.9279 val_acc:0.6822
epoch=99 train_loss:0.0086 train_acc:0.9981 validating val_loss:3.8456 val_acc:0.6793
epoch=100 train_loss:0.0087 train_acc:0.9979 validating val_loss:3.9911 val_acc:0.6840
epoch=101 train_loss:0.0090 train_acc:0.9978 validating val_loss:4.0356 val_acc:0.6741
epoch=102 train_loss:0.0094 train_acc:0.9979 validating val_loss:3.9603 val_acc:0.6767
epoch=103 train_loss:0.0089 train_acc:0.9978 validating val_loss:3.7826 val_acc:0.6789
Epoch   103: reducing learning rate of group 0 to 1.0000e-08.
epoch=104 train_loss:0.0097 train_acc:0.9976 validating val_loss:3.8756 val_acc:0.6819
epoch=105 train_loss:0.0089 train_acc:0.9981 validating val_loss:3.8905 val_acc:0.6801
epoch=106 train_loss:0.0090 train_acc:0.9980 validating val_loss:4.2818 val_acc:0.6743
epoch=107 train_loss:0.0098 train_acc:0.9978 validating val_loss:3.8459 val_acc:0.6777
epoch=108 train_loss:0.0086 train_acc:0.9981 validating val_loss:4.0958 val_acc:0.6760
epoch=109 train_loss:0.0096 train_acc:0.9976 validating val_loss:4.1124 val_acc:0.6731
epoch=110 train_loss:0.0088 train_acc:0.9979 validating val_loss:3.9889 val_acc:0.6788
epoch=111 train_loss:0.0087 train_acc:0.9980 validating val_loss:3.7133 val_acc:0.6858
epoch=112 train_loss:0.0089 train_acc:0.9982 validating val_loss:3.8188 val_acc:0.6780
epoch=113 train_loss:0.0088 train_acc:0.9980 validating val_loss:3.8930 val_acc:0.6785
epoch=114 train_loss:0.0090 train_acc:0.9978 validating val_loss:4.0664 val_acc:0.6817
epoch=115 train_loss:0.0090 train_acc:0.9977 validating val_loss:4.2149 val_acc:0.6697
epoch=116 train_loss:0.0086 train_acc:0.9983 validating val_loss:3.8749 val_acc:0.6797
epoch=117 train_loss:0.0086 train_acc:0.9980 validating val_loss:3.9818 val_acc:0.6743
epoch=118 train_loss:0.0087 train_acc:0.9979 validating val_loss:3.8835 val_acc:0.6770
epoch=119 train_loss:0.0093 train_acc:0.9980 validating val_loss:3.9309 val_acc:0.6772
epoch=120 train_loss:0.0092 train_acc:0.9977 validating val_loss:4.1934 val_acc:0.6759
epoch=121 train_loss:0.0088 train_acc:0.9981 validating val_loss:4.4696 val_acc:0.6714
epoch=122 train_loss:0.0086 train_acc:0.9980 validating val_loss:3.8867 val_acc:0.6818
epoch=123 train_loss:0.0091 train_acc:0.9978 validating val_loss:3.7838 val_acc:0.6856
epoch=124 train_loss:0.0090 train_acc:0.9980 validating val_loss:3.8033 val_acc:0.6832
epoch=125 train_loss:0.0086 train_acc:0.9982 validating val_loss:3.9934 val_acc:0.6783
epoch=126 train_loss:0.0088 train_acc:0.9976 validating val_loss:3.5728 val_acc:0.6852
epoch=127 train_loss:0.0103 train_acc:0.9978 validating val_loss:4.3025 val_acc:0.6718
epoch=128 train_loss:0.0095 train_acc:0.9977 validating val_loss:4.2913 val_acc:0.6732
epoch=129 train_loss:0.0093 train_acc:0.9976 validating val_loss:3.7132 val_acc:0.6794
epoch=130 train_loss:0.0098 train_acc:0.9977 validating val_loss:3.6658 val_acc:0.6896
epoch=131 train_loss:0.0098 train_acc:0.9978 validating val_loss:3.7829 val_acc:0.6834
epoch=132 train_loss:0.0096 train_acc:0.9975 validating val_loss:4.0022 val_acc:0.6729
epoch=133 train_loss:0.0090 train_acc:0.9978 validating val_loss:4.1275 val_acc:0.6767
epoch=134 train_loss:0.0096 train_acc:0.9977 validating val_loss:3.9691 val_acc:0.6741
epoch=135 train_loss:0.0091 train_acc:0.9976 validating val_loss:4.2503 val_acc:0.6726
epoch=136 train_loss:0.0092 train_acc:0.9978 validating val_loss:3.6208 val_acc:0.6811
epoch=137 train_loss:0.0087 train_acc:0.9980 validating val_loss:3.8570 val_acc:0.6799
epoch=138 train_loss:0.0091 train_acc:0.9978 validating val_loss:3.9000 val_acc:0.6757
epoch=139 train_loss:0.0088 train_acc:0.9981 validating val_loss:3.8464 val_acc:0.6796
epoch=140 train_loss:0.0087 train_acc:0.9979 validating val_loss:4.1786 val_acc:0.6702
epoch=141 train_loss:0.0100 train_acc:0.9973 validating val_loss:4.4820 val_acc:0.6678
epoch=142 train_loss:0.0088 train_acc:0.9978 validating val_loss:4.0538 val_acc:0.6692
epoch=143 train_loss:0.0095 train_acc:0.9979 validating val_loss:4.0303 val_acc:0.6830
epoch=144 train_loss:0.0093 train_acc:0.9978 validating val_loss:4.0500 val_acc:0.6702
epoch=145 train_loss:0.0096 train_acc:0.9973 validating val_loss:3.8966 val_acc:0.6736
epoch=146 train_loss:0.0099 train_acc:0.9979 validating val_loss:4.2455 val_acc:0.6664
epoch=147 train_loss:0.0090 train_acc:0.9980 validating val_loss:3.9367 val_acc:0.6732
epoch=148 train_loss:0.0091 train_acc:0.9978 validating val_loss:3.9854 val_acc:0.6756
epoch=149 train_loss:0.0092 train_acc:0.9979 validating val_loss:4.1011 val_acc:0.6731
epoch=150 train_loss:0.0089 train_acc:0.9978 validating val_loss:3.7892 val_acc:0.6760
epoch=151 train_loss:0.0088 train_acc:0.9979 validating val_loss:3.8139 val_acc:0.6791
epoch=152 train_loss:0.0091 train_acc:0.9977 validating val_loss:3.9156 val_acc:0.6807
epoch=153 train_loss:0.0087 train_acc:0.9981 validating val_loss:3.7933 val_acc:0.6825
epoch=154 train_loss:0.0087 train_acc:0.9979 validating val_loss:4.0099 val_acc:0.6692
epoch=155 train_loss:0.0090 train_acc:0.9980 validating val_loss:3.8434 val_acc:0.6835
epoch=156 train_loss:0.0087 train_acc:0.9980 validating val_loss:3.7120 val_acc:0.6804
epoch=157 train_loss:0.0091 train_acc:0.9978 validating val_loss:3.8823 val_acc:0.6833
epoch=158 train_loss:0.0093 train_acc:0.9979 validating val_loss:3.9375 val_acc:0.6786
epoch=159 train_loss:0.0099 train_acc:0.9978 validating val_loss:4.5707 val_acc:0.6728
epoch=160 train_loss:0.0092 train_acc:0.9978 validating val_loss:3.8006 val_acc:0.6870
epoch=161 train_loss:0.0088 train_acc:0.9981 validating val_loss:4.2219 val_acc:0.6722
epoch=162 train_loss:0.0088 train_acc:0.9977 validating val_loss:3.8944 val_acc:0.6798
epoch=163 train_loss:0.0089 train_acc:0.9979 validating val_loss:3.6525 val_acc:0.6852
epoch=164 train_loss:0.0090 train_acc:0.9979 validating val_loss:4.0288 val_acc:0.6763
epoch=165 train_loss:0.0090 train_acc:0.9979 validating val_loss:4.0689 val_acc:0.6705
epoch=166 train_loss:0.0091 train_acc:0.9980 validating val_loss:3.9446 val_acc:0.6839
epoch=167 train_loss:0.0089 train_acc:0.9978 validating val_loss:3.8564 val_acc:0.6825
epoch=168 train_loss:0.0091 train_acc:0.9979 validating val_loss:4.0305 val_acc:0.6767
epoch=169 train_loss:0.0092 train_acc:0.9980 validating val_loss:4.3845 val_acc:0.6726
epoch=170 train_loss:0.0095 train_acc:0.9980 validating val_loss:4.0393 val_acc:0.6784
epoch=171 train_loss:0.0089 train_acc:0.9978 validating val_loss:3.8286 val_acc:0.6816
epoch=172 train_loss:0.0086 train_acc:0.9978 validating val_loss:3.8922 val_acc:0.6797
epoch=173 train_loss:0.0088 train_acc:0.9981 validating val_loss:4.0461 val_acc:0.6778
epoch=174 train_loss:0.0087 train_acc:0.9977 validating val_loss:4.3242 val_acc:0.6675
epoch=175 train_loss:0.0086 train_acc:0.9980 validating val_loss:4.0195 val_acc:0.6745
epoch=176 train_loss:0.0094 train_acc:0.9977 validating val_loss:3.7845 val_acc:0.6796
epoch=177 train_loss:0.0089 train_acc:0.9979 validating val_loss:3.7442 val_acc:0.6781
epoch=178 train_loss:0.0095 train_acc:0.9979 validating val_loss:4.1918 val_acc:0.6709
epoch=179 train_loss:0.0091 train_acc:0.9979 validating val_loss:3.8874 val_acc:0.6838
epoch=180 train_loss:0.0088 train_acc:0.9980 validating val_loss:3.9486 val_acc:0.6791
epoch=181 train_loss:0.0095 train_acc:0.9976 validating val_loss:4.1145 val_acc:0.6707
epoch=182 train_loss:0.0091 train_acc:0.9979 validating val_loss:3.9662 val_acc:0.6728
epoch=183 train_loss:0.0093 train_acc:0.9977 validating val_loss:3.7130 val_acc:0.6841
epoch=184 train_loss:0.0097 train_acc:0.9977 validating val_loss:4.0967 val_acc:0.6725
epoch=185 train_loss:0.0093 train_acc:0.9977 validating val_loss:3.8537 val_acc:0.6831
epoch=186 train_loss:0.0101 train_acc:0.9975 validating val_loss:4.0867 val_acc:0.6729
epoch=187 train_loss:0.0091 train_acc:0.9976 validating val_loss:3.7347 val_acc:0.6820
epoch=188 train_loss:0.0091 train_acc:0.9979 validating val_loss:4.1728 val_acc:0.6708
epoch=189 train_loss:0.0089 train_acc:0.9979 validating val_loss:4.0829 val_acc:0.6734
epoch=190 train_loss:0.0085 train_acc:0.9978 validating val_loss:3.8062 val_acc:0.6799
epoch=191 train_loss:0.0087 train_acc:0.9979 validating val_loss:4.0916 val_acc:0.6737
epoch=192 train_loss:0.0087 train_acc:0.9980 validating val_loss:3.9732 val_acc:0.6718
epoch=193 train_loss:0.0094 train_acc:0.9975 validating val_loss:3.9431 val_acc:0.6792
epoch=194 train_loss:0.0085 train_acc:0.9980 validating val_loss:3.8520 val_acc:0.6791
epoch=195 train_loss:0.0097 train_acc:0.9977 validating val_loss:3.7832 val_acc:0.6858
epoch=196 train_loss:0.0095 train_acc:0.9978 validating val_loss:3.8848 val_acc:0.6828
epoch=197 train_loss:0.0097 train_acc:0.9977 validating val_loss:4.0152 val_acc:0.6734
epoch=198 train_loss:0.0095 train_acc:0.9977 validating val_loss:3.8402 val_acc:0.6795
epoch=199 train_loss:0.0087 train_acc:0.9981 validating val_loss:4.0408 val_acc:0.6748
Finished Training
