batch_size=64
nohup: ignoring input
1.0.1.post2
cuda is available
start training
validating val_loss:6.3481 val_acc:0.1000
epoch=1 train_loss:2.0314 train_acc:0.2571 validating val_loss:1.6605 val_acc:0.3501
epoch=2 train_loss:1.6742 train_acc:0.3661 validating val_loss:1.6454 val_acc:0.3918
epoch=3 train_loss:1.5031 train_acc:0.4555 validating val_loss:1.2736 val_acc:0.5398
epoch=4 train_loss:1.3449 train_acc:0.5261 validating val_loss:1.1863 val_acc:0.5786
epoch=5 train_loss:1.2442 train_acc:0.5646 validating val_loss:1.0803 val_acc:0.6273
epoch=6 train_loss:1.1790 train_acc:0.5916 validating val_loss:1.0285 val_acc:0.6343
epoch=7 train_loss:1.1127 train_acc:0.6172 validating val_loss:0.9454 val_acc:0.6653
epoch=8 train_loss:1.0489 train_acc:0.6433 validating val_loss:0.9706 val_acc:0.6789
epoch=9 train_loss:0.9884 train_acc:0.6686 validating val_loss:0.7866 val_acc:0.7362
epoch=10 train_loss:0.9482 train_acc:0.6855 validating val_loss:0.7529 val_acc:0.7456
epoch=11 train_loss:0.9018 train_acc:0.6987 validating val_loss:0.7952 val_acc:0.7536
epoch=12 train_loss:0.8711 train_acc:0.7121 validating val_loss:0.7116 val_acc:0.7571
epoch=13 train_loss:0.8431 train_acc:0.7211 validating val_loss:0.7046 val_acc:0.7601
epoch=14 train_loss:0.8128 train_acc:0.7333 validating val_loss:0.6903 val_acc:0.7727
epoch=15 train_loss:0.7856 train_acc:0.7406 validating val_loss:0.7329 val_acc:0.7577
epoch=16 train_loss:0.7762 train_acc:0.7456 validating val_loss:0.5773 val_acc:0.8076
epoch=17 train_loss:0.7555 train_acc:0.7524 validating val_loss:0.6132 val_acc:0.7981
epoch=18 train_loss:0.7361 train_acc:0.7595 validating val_loss:0.5542 val_acc:0.8188
epoch=19 train_loss:0.7247 train_acc:0.7633 validating val_loss:0.5589 val_acc:0.8137
epoch=20 train_loss:0.7164 train_acc:0.7671 validating val_loss:0.5832 val_acc:0.8071
epoch=21 train_loss:0.6965 train_acc:0.7729 validating val_loss:0.6449 val_acc:0.7698
epoch=22 train_loss:0.6925 train_acc:0.7750 validating val_loss:0.5775 val_acc:0.8088
epoch=23 train_loss:0.6770 train_acc:0.7783 validating val_loss:0.5272 val_acc:0.8290
epoch=24 train_loss:0.6714 train_acc:0.7819 validating val_loss:0.5279 val_acc:0.8238
epoch=25 train_loss:0.6633 train_acc:0.7836 validating val_loss:0.5450 val_acc:0.8219
epoch=26 train_loss:0.6565 train_acc:0.7862 validating val_loss:0.4813 val_acc:0.8393
epoch=27 train_loss:0.6461 train_acc:0.7905 validating val_loss:0.5321 val_acc:0.8281
epoch=28 train_loss:0.6461 train_acc:0.7916 validating val_loss:0.5148 val_acc:0.8245
epoch=29 train_loss:0.6386 train_acc:0.7919 validating val_loss:0.5254 val_acc:0.8267
epoch=30 train_loss:0.6402 train_acc:0.7929 validating val_loss:0.5044 val_acc:0.8331
epoch=31 train_loss:0.6246 train_acc:0.7983 validating val_loss:0.5093 val_acc:0.8279
epoch=32 train_loss:0.6234 train_acc:0.7976 validating val_loss:0.5309 val_acc:0.8175
epoch=33 train_loss:0.6230 train_acc:0.7986 validating val_loss:0.4876 val_acc:0.8384
epoch=34 train_loss:0.6135 train_acc:0.8007 validating val_loss:0.4690 val_acc:0.8484
epoch=35 train_loss:0.6046 train_acc:0.8028 validating val_loss:0.5187 val_acc:0.8251
epoch=36 train_loss:0.6012 train_acc:0.8058 validating val_loss:0.4967 val_acc:0.8350
epoch=37 train_loss:0.6012 train_acc:0.8049 validating val_loss:0.5558 val_acc:0.8144
epoch=38 train_loss:0.6028 train_acc:0.8037 validating val_loss:0.4614 val_acc:0.8421
epoch=39 train_loss:0.5889 train_acc:0.8095 validating val_loss:0.5550 val_acc:0.8141
epoch=40 train_loss:0.5882 train_acc:0.8091 validating val_loss:0.4732 val_acc:0.8413
epoch=41 train_loss:0.5873 train_acc:0.8108 validating val_loss:0.4579 val_acc:0.8457
epoch=42 train_loss:0.5861 train_acc:0.8103 validating val_loss:0.4435 val_acc:0.8557
epoch=43 train_loss:0.5840 train_acc:0.8100 validating val_loss:0.4988 val_acc:0.8280
epoch=44 train_loss:0.5732 train_acc:0.8139 validating val_loss:0.4555 val_acc:0.8526
epoch=45 train_loss:0.5762 train_acc:0.8138 validating val_loss:0.4689 val_acc:0.8431
epoch=46 train_loss:0.5693 train_acc:0.8170 validating val_loss:0.5006 val_acc:0.8294
epoch=47 train_loss:0.5709 train_acc:0.8169 validating val_loss:0.5236 val_acc:0.8305
epoch=48 train_loss:0.5740 train_acc:0.8149 validating val_loss:0.4452 val_acc:0.8525
epoch=49 train_loss:0.5595 train_acc:0.8201 validating val_loss:0.4620 val_acc:0.8453
epoch=50 train_loss:0.5584 train_acc:0.8176 validating val_loss:0.4386 val_acc:0.8541
epoch=51 train_loss:0.5559 train_acc:0.8196 validating val_loss:0.4294 val_acc:0.8579
epoch=52 train_loss:0.5642 train_acc:0.8175 validating val_loss:0.4707 val_acc:0.8423
epoch=53 train_loss:0.5624 train_acc:0.8195 validating val_loss:0.4722 val_acc:0.8440
epoch=54 train_loss:0.5611 train_acc:0.8169 validating val_loss:0.4265 val_acc:0.8617
epoch=55 train_loss:0.5568 train_acc:0.8221 validating val_loss:0.4860 val_acc:0.8378
epoch=56 train_loss:0.5512 train_acc:0.8206 validating val_loss:0.4264 val_acc:0.8581
epoch=57 train_loss:0.5514 train_acc:0.8214 validating val_loss:0.4829 val_acc:0.8328
epoch=58 train_loss:0.5430 train_acc:0.8247 validating val_loss:0.5006 val_acc:0.8307
epoch=59 train_loss:0.5490 train_acc:0.8219 validating val_loss:0.4725 val_acc:0.8446
epoch=60 train_loss:0.5479 train_acc:0.8247 validating val_loss:0.4201 val_acc:0.8627
epoch=61 train_loss:0.5428 train_acc:0.8251 validating val_loss:0.4076 val_acc:0.8670
epoch=62 train_loss:0.5334 train_acc:0.8265 validating val_loss:0.4388 val_acc:0.8571
epoch=63 train_loss:0.5369 train_acc:0.8260 validating val_loss:0.4585 val_acc:0.8472
epoch=64 train_loss:0.5384 train_acc:0.8258 validating val_loss:0.4202 val_acc:0.8538
epoch=65 train_loss:0.5396 train_acc:0.8264 validating val_loss:0.4754 val_acc:0.8474
epoch=66 train_loss:0.5397 train_acc:0.8259 validating val_loss:0.4264 val_acc:0.8600
epoch=67 train_loss:0.5302 train_acc:0.8274 validating val_loss:0.4199 val_acc:0.8613
epoch=68 train_loss:0.5249 train_acc:0.8311 validating val_loss:0.4323 val_acc:0.8508
epoch=69 train_loss:0.5382 train_acc:0.8270 validating val_loss:0.4591 val_acc:0.8476
epoch=70 train_loss:0.5418 train_acc:0.8251 validating val_loss:0.3845 val_acc:0.8732
epoch=71 train_loss:0.5358 train_acc:0.8272 validating val_loss:0.4608 val_acc:0.8459
epoch=72 train_loss:0.5321 train_acc:0.8284 validating val_loss:0.4529 val_acc:0.8479
epoch=73 train_loss:0.5330 train_acc:0.8295 validating val_loss:0.3894 val_acc:0.8746
epoch=74 train_loss:0.5281 train_acc:0.8285 validating val_loss:0.4111 val_acc:0.8642
epoch=75 train_loss:0.5380 train_acc:0.8261 validating val_loss:0.4852 val_acc:0.8332
epoch=76 train_loss:0.5245 train_acc:0.8296 validating val_loss:0.4313 val_acc:0.8601
epoch=77 train_loss:0.5209 train_acc:0.8337 validating val_loss:0.4500 val_acc:0.8471
epoch=78 train_loss:0.5226 train_acc:0.8303 validating val_loss:0.4473 val_acc:0.8493
epoch=79 train_loss:0.5184 train_acc:0.8340 validating val_loss:0.4049 val_acc:0.8674
epoch=80 train_loss:0.5107 train_acc:0.8354 validating val_loss:0.3858 val_acc:0.8708
epoch=81 train_loss:0.5162 train_acc:0.8334 validating val_loss:0.4284 val_acc:0.8588
Epoch    81: reducing learning rate of group 0 to 1.0000e-02.
epoch=82 train_loss:0.3742 train_acc:0.8794 validating val_loss:0.2887 val_acc:0.9033
epoch=83 train_loss:0.3213 train_acc:0.8956 validating val_loss:0.2694 val_acc:0.9105
epoch=84 train_loss:0.3041 train_acc:0.9018 validating val_loss:0.2655 val_acc:0.9101
epoch=85 train_loss:0.2873 train_acc:0.9054 validating val_loss:0.2653 val_acc:0.9109
epoch=86 train_loss:0.2809 train_acc:0.9070 validating val_loss:0.2528 val_acc:0.9146
epoch=87 train_loss:0.2740 train_acc:0.9106 validating val_loss:0.2533 val_acc:0.9124
epoch=88 train_loss:0.2675 train_acc:0.9139 validating val_loss:0.2550 val_acc:0.9132
epoch=89 train_loss:0.2564 train_acc:0.9175 validating val_loss:0.2456 val_acc:0.9157
epoch=90 train_loss:0.2554 train_acc:0.9175 validating val_loss:0.2388 val_acc:0.9172
epoch=91 train_loss:0.2422 train_acc:0.9224 validating val_loss:0.2446 val_acc:0.9143
epoch=92 train_loss:0.2444 train_acc:0.9204 validating val_loss:0.2407 val_acc:0.9191
epoch=93 train_loss:0.2413 train_acc:0.9218 validating val_loss:0.2395 val_acc:0.9182
epoch=94 train_loss:0.2343 train_acc:0.9241 validating val_loss:0.2377 val_acc:0.9197
epoch=95 train_loss:0.2295 train_acc:0.9250 validating val_loss:0.2432 val_acc:0.9166
epoch=96 train_loss:0.2293 train_acc:0.9246 validating val_loss:0.2412 val_acc:0.9178
epoch=97 train_loss:0.2282 train_acc:0.9257 validating val_loss:0.2393 val_acc:0.9197
epoch=98 train_loss:0.2201 train_acc:0.9275 validating val_loss:0.2356 val_acc:0.9195
epoch=99 train_loss:0.2187 train_acc:0.9278 validating val_loss:0.2364 val_acc:0.9207
epoch=100 train_loss:0.2159 train_acc:0.9286 validating val_loss:0.2340 val_acc:0.9203
epoch=101 train_loss:0.2102 train_acc:0.9305 validating val_loss:0.2337 val_acc:0.9226
epoch=102 train_loss:0.2054 train_acc:0.9327 validating val_loss:0.2514 val_acc:0.9131
epoch=103 train_loss:0.2068 train_acc:0.9339 validating val_loss:0.2343 val_acc:0.9209
epoch=104 train_loss:0.2028 train_acc:0.9327 validating val_loss:0.2368 val_acc:0.9203
epoch=105 train_loss:0.2036 train_acc:0.9340 validating val_loss:0.2470 val_acc:0.9177
epoch=106 train_loss:0.1977 train_acc:0.9353 validating val_loss:0.2391 val_acc:0.9215
epoch=107 train_loss:0.1985 train_acc:0.9351 validating val_loss:0.2375 val_acc:0.9228
epoch=108 train_loss:0.1943 train_acc:0.9360 validating val_loss:0.2481 val_acc:0.9175
epoch=109 train_loss:0.1970 train_acc:0.9348 validating val_loss:0.2356 val_acc:0.9210
epoch=110 train_loss:0.1924 train_acc:0.9374 validating val_loss:0.2362 val_acc:0.9201
epoch=111 train_loss:0.1918 train_acc:0.9378 validating val_loss:0.2389 val_acc:0.9192
epoch=112 train_loss:0.1886 train_acc:0.9388 validating val_loss:0.2355 val_acc:0.9211
Epoch   112: reducing learning rate of group 0 to 1.0000e-03.
epoch=113 train_loss:0.1701 train_acc:0.9442 validating val_loss:0.2241 val_acc:0.9229
epoch=114 train_loss:0.1579 train_acc:0.9483 validating val_loss:0.2194 val_acc:0.9258
epoch=115 train_loss:0.1608 train_acc:0.9483 validating val_loss:0.2198 val_acc:0.9250
epoch=116 train_loss:0.1515 train_acc:0.9513 validating val_loss:0.2158 val_acc:0.9276
epoch=117 train_loss:0.1537 train_acc:0.9494 validating val_loss:0.2202 val_acc:0.9263
epoch=118 train_loss:0.1469 train_acc:0.9516 validating val_loss:0.2195 val_acc:0.9262
epoch=119 train_loss:0.1450 train_acc:0.9521 validating val_loss:0.2205 val_acc:0.9270
epoch=120 train_loss:0.1464 train_acc:0.9521 validating val_loss:0.2169 val_acc:0.9278
epoch=121 train_loss:0.1439 train_acc:0.9535 validating val_loss:0.2190 val_acc:0.9268
epoch=122 train_loss:0.1394 train_acc:0.9539 validating val_loss:0.2192 val_acc:0.9267
epoch=123 train_loss:0.1427 train_acc:0.9549 validating val_loss:0.2241 val_acc:0.9271
epoch=124 train_loss:0.1405 train_acc:0.9540 validating val_loss:0.2187 val_acc:0.9276
epoch=125 train_loss:0.1388 train_acc:0.9542 validating val_loss:0.2195 val_acc:0.9293
epoch=126 train_loss:0.1423 train_acc:0.9535 validating val_loss:0.2197 val_acc:0.9274
epoch=127 train_loss:0.1364 train_acc:0.9564 validating val_loss:0.2192 val_acc:0.9273
Epoch   127: reducing learning rate of group 0 to 1.0000e-04.
epoch=128 train_loss:0.1373 train_acc:0.9560 validating val_loss:0.2203 val_acc:0.9269
epoch=129 train_loss:0.1376 train_acc:0.9553 validating val_loss:0.2194 val_acc:0.9290
epoch=130 train_loss:0.1357 train_acc:0.9556 validating val_loss:0.2168 val_acc:0.9288
epoch=131 train_loss:0.1351 train_acc:0.9567 validating val_loss:0.2214 val_acc:0.9278
epoch=132 train_loss:0.1341 train_acc:0.9558 validating val_loss:0.2216 val_acc:0.9276
epoch=133 train_loss:0.1351 train_acc:0.9559 validating val_loss:0.2176 val_acc:0.9293
epoch=134 train_loss:0.1338 train_acc:0.9579 validating val_loss:0.2187 val_acc:0.9271
epoch=135 train_loss:0.1320 train_acc:0.9575 validating val_loss:0.2191 val_acc:0.9287
epoch=136 train_loss:0.1323 train_acc:0.9565 validating val_loss:0.2179 val_acc:0.9284
epoch=137 train_loss:0.1336 train_acc:0.9563 validating val_loss:0.2183 val_acc:0.9278
epoch=138 train_loss:0.1364 train_acc:0.9555 validating val_loss:0.2188 val_acc:0.9275
Epoch   138: reducing learning rate of group 0 to 1.0000e-05.
epoch=139 train_loss:0.1324 train_acc:0.9568 validating val_loss:0.2172 val_acc:0.9292
epoch=140 train_loss:0.1332 train_acc:0.9562 validating val_loss:0.2197 val_acc:0.9276
epoch=141 train_loss:0.1343 train_acc:0.9569 validating val_loss:0.2190 val_acc:0.9277
epoch=142 train_loss:0.1328 train_acc:0.9561 validating val_loss:0.2170 val_acc:0.9296
epoch=143 train_loss:0.1347 train_acc:0.9567 validating val_loss:0.2188 val_acc:0.9278
epoch=144 train_loss:0.1317 train_acc:0.9576 validating val_loss:0.2192 val_acc:0.9279
epoch=145 train_loss:0.1328 train_acc:0.9571 validating val_loss:0.2215 val_acc:0.9290
epoch=146 train_loss:0.1315 train_acc:0.9568 validating val_loss:0.2189 val_acc:0.9282
epoch=147 train_loss:0.1350 train_acc:0.9565 validating val_loss:0.2201 val_acc:0.9294
epoch=148 train_loss:0.1357 train_acc:0.9562 validating val_loss:0.2186 val_acc:0.9276
epoch=149 train_loss:0.1363 train_acc:0.9559 validating val_loss:0.2177 val_acc:0.9280
Epoch   149: reducing learning rate of group 0 to 1.0000e-06.
epoch=150 train_loss:0.1347 train_acc:0.9554 validating val_loss:0.2198 val_acc:0.9286
epoch=151 train_loss:0.1358 train_acc:0.9550 validating val_loss:0.2168 val_acc:0.9284
epoch=152 train_loss:0.1352 train_acc:0.9555 validating val_loss:0.2189 val_acc:0.9293
epoch=153 train_loss:0.1335 train_acc:0.9570 validating val_loss:0.2162 val_acc:0.9287
epoch=154 train_loss:0.1330 train_acc:0.9561 validating val_loss:0.2187 val_acc:0.9285
epoch=155 train_loss:0.1337 train_acc:0.9557 validating val_loss:0.2200 val_acc:0.9286
epoch=156 train_loss:0.1317 train_acc:0.9573 validating val_loss:0.2180 val_acc:0.9281
epoch=157 train_loss:0.1313 train_acc:0.9572 validating val_loss:0.2187 val_acc:0.9268
epoch=158 train_loss:0.1336 train_acc:0.9570 validating val_loss:0.2204 val_acc:0.9283
epoch=159 train_loss:0.1316 train_acc:0.9563 validating val_loss:0.2196 val_acc:0.9285
epoch=160 train_loss:0.1330 train_acc:0.9565 validating val_loss:0.2196 val_acc:0.9281
Epoch   160: reducing learning rate of group 0 to 1.0000e-07.
epoch=161 train_loss:0.1292 train_acc:0.9573 validating val_loss:0.2200 val_acc:0.9287
epoch=162 train_loss:0.1316 train_acc:0.9566 validating val_loss:0.2194 val_acc:0.9266
epoch=163 train_loss:0.1322 train_acc:0.9564 validating val_loss:0.2182 val_acc:0.9289
epoch=164 train_loss:0.1361 train_acc:0.9555 validating val_loss:0.2191 val_acc:0.9283
epoch=165 train_loss:0.1320 train_acc:0.9563 validating val_loss:0.2179 val_acc:0.9274
epoch=166 train_loss:0.1389 train_acc:0.9543 validating val_loss:0.2179 val_acc:0.9274
epoch=167 train_loss:0.1331 train_acc:0.9569 validating val_loss:0.2171 val_acc:0.9281
epoch=168 train_loss:0.1331 train_acc:0.9571 validating val_loss:0.2176 val_acc:0.9279
epoch=169 train_loss:0.1324 train_acc:0.9560 validating val_loss:0.2191 val_acc:0.9299
epoch=170 train_loss:0.1337 train_acc:0.9555 validating val_loss:0.2195 val_acc:0.9288
epoch=171 train_loss:0.1329 train_acc:0.9576 validating val_loss:0.2211 val_acc:0.9275
Epoch   171: reducing learning rate of group 0 to 1.0000e-08.
epoch=172 train_loss:0.1312 train_acc:0.9579 validating val_loss:0.2175 val_acc:0.9285
epoch=173 train_loss:0.1358 train_acc:0.9555 validating val_loss:0.2196 val_acc:0.9289
epoch=174 train_loss:0.1331 train_acc:0.9562 validating val_loss:0.2183 val_acc:0.9285
epoch=175 train_loss:0.1294 train_acc:0.9581 validating val_loss:0.2170 val_acc:0.9278
epoch=176 train_loss:0.1365 train_acc:0.9551 validating val_loss:0.2174 val_acc:0.9287
epoch=177 train_loss:0.1329 train_acc:0.9562 validating val_loss:0.2210 val_acc:0.9289
epoch=178 train_loss:0.1308 train_acc:0.9576 validating val_loss:0.2179 val_acc:0.9286
epoch=179 train_loss:0.1325 train_acc:0.9577 validating val_loss:0.2181 val_acc:0.9290
epoch=180 train_loss:0.1320 train_acc:0.9566 validating val_loss:0.2182 val_acc:0.9301
epoch=181 train_loss:0.1310 train_acc:0.9575 validating val_loss:0.2198 val_acc:0.9298
epoch=182 train_loss:0.1365 train_acc:0.9553 validating val_loss:0.2172 val_acc:0.9278
epoch=183 train_loss:0.1315 train_acc:0.9562 validating val_loss:0.2193 val_acc:0.9282
epoch=184 train_loss:0.1305 train_acc:0.9583 validating val_loss:0.2217 val_acc:0.9298
epoch=185 train_loss:0.1293 train_acc:0.9580 validating val_loss:0.2178 val_acc:0.9282
epoch=186 train_loss:0.1362 train_acc:0.9558 validating val_loss:0.2189 val_acc:0.9289
epoch=187 train_loss:0.1337 train_acc:0.9568 validating val_loss:0.2184 val_acc:0.9276
epoch=188 train_loss:0.1355 train_acc:0.9560 validating val_loss:0.2215 val_acc:0.9276
epoch=189 train_loss:0.1344 train_acc:0.9569 validating val_loss:0.2205 val_acc:0.9275
epoch=190 train_loss:0.1304 train_acc:0.9575 validating val_loss:0.2211 val_acc:0.9288
epoch=191 train_loss:0.1357 train_acc:0.9551 validating val_loss:0.2165 val_acc:0.9279
epoch=192 train_loss:0.1326 train_acc:0.9565 validating val_loss:0.2192 val_acc:0.9275
epoch=193 train_loss:0.1338 train_acc:0.9563 validating val_loss:0.2177 val_acc:0.9288
epoch=194 train_loss:0.1375 train_acc:0.9552 validating val_loss:0.2180 val_acc:0.9290
epoch=195 train_loss:0.1338 train_acc:0.9572 validating val_loss:0.2184 val_acc:0.9276
epoch=196 train_loss:0.1327 train_acc:0.9563 validating val_loss:0.2171 val_acc:0.9280
epoch=197 train_loss:0.1351 train_acc:0.9554 validating val_loss:0.2183 val_acc:0.9285
epoch=198 train_loss:0.1334 train_acc:0.9566 validating val_loss:0.2178 val_acc:0.9288
epoch=199 train_loss:0.1324 train_acc:0.9568 validating val_loss:0.2170 val_acc:0.9283
Finished Training
