nohup: ignoring input
1.0.1.post2
cuda is available
start training
validating val_loss:2.3051 val_acc:0.1076
epoch=1 train_loss:1.6267 train_acc:0.3940 validating val_loss:1.7418 val_acc:0.4319
epoch=2 train_loss:1.2311 train_acc:0.5630 validating val_loss:1.5530 val_acc:0.5297
epoch=3 train_loss:1.0668 train_acc:0.6256 validating val_loss:1.2954 val_acc:0.6708
epoch=4 train_loss:0.9658 train_acc:0.6597 validating val_loss:1.3382 val_acc:0.6570
epoch=5 train_loss:0.8898 train_acc:0.6902 validating val_loss:1.1379 val_acc:0.7420
epoch=6 train_loss:0.8276 train_acc:0.7116 validating val_loss:1.0978 val_acc:0.7428
epoch=7 train_loss:0.7857 train_acc:0.7279 validating val_loss:1.0416 val_acc:0.7571
epoch=8 train_loss:0.7436 train_acc:0.7416 validating val_loss:1.0156 val_acc:0.7647
epoch=9 train_loss:0.7170 train_acc:0.7506 validating val_loss:1.0113 val_acc:0.7848
epoch=10 train_loss:0.6917 train_acc:0.7621 validating val_loss:0.9284 val_acc:0.7963
epoch=11 train_loss:0.6700 train_acc:0.7708 validating val_loss:0.9680 val_acc:0.7996
epoch=12 train_loss:0.6535 train_acc:0.7745 validating val_loss:0.8927 val_acc:0.8054
epoch=13 train_loss:0.6332 train_acc:0.7816 validating val_loss:0.9035 val_acc:0.7846
epoch=14 train_loss:0.6241 train_acc:0.7851 validating val_loss:0.9031 val_acc:0.7998
epoch=15 train_loss:0.6070 train_acc:0.7913 validating val_loss:0.8788 val_acc:0.7986
epoch=16 train_loss:0.5908 train_acc:0.7961 validating val_loss:0.8459 val_acc:0.8146
epoch=17 train_loss:0.5858 train_acc:0.7974 validating val_loss:0.8794 val_acc:0.7890
epoch=18 train_loss:0.5757 train_acc:0.8019 validating val_loss:0.8492 val_acc:0.8108
epoch=19 train_loss:0.5700 train_acc:0.8039 validating val_loss:0.8523 val_acc:0.7904
epoch=20 train_loss:0.5607 train_acc:0.8076 validating val_loss:0.7934 val_acc:0.8360
epoch=21 train_loss:0.5460 train_acc:0.8126 validating val_loss:0.7845 val_acc:0.8327
epoch=22 train_loss:0.5419 train_acc:0.8160 validating val_loss:0.8114 val_acc:0.8023
epoch=23 train_loss:0.5337 train_acc:0.8175 validating val_loss:0.7491 val_acc:0.8396
epoch=24 train_loss:0.5241 train_acc:0.8205 validating val_loss:0.7712 val_acc:0.8156
epoch=25 train_loss:0.5287 train_acc:0.8199 validating val_loss:0.7750 val_acc:0.8252
epoch=26 train_loss:0.5183 train_acc:0.8225 validating val_loss:0.7599 val_acc:0.8172
epoch=27 train_loss:0.5157 train_acc:0.8242 validating val_loss:0.7491 val_acc:0.8348
epoch=28 train_loss:0.5104 train_acc:0.8271 validating val_loss:0.7437 val_acc:0.8258
epoch=29 train_loss:0.5007 train_acc:0.8294 validating val_loss:0.7641 val_acc:0.8129
epoch=30 train_loss:0.5076 train_acc:0.8265 validating val_loss:0.7415 val_acc:0.8410
epoch=31 train_loss:0.5089 train_acc:0.8251 validating val_loss:0.6860 val_acc:0.8432
epoch=32 train_loss:0.5009 train_acc:0.8292 validating val_loss:0.7355 val_acc:0.8270
epoch=33 train_loss:0.4939 train_acc:0.8311 validating val_loss:0.6891 val_acc:0.8464
epoch=34 train_loss:0.4906 train_acc:0.8313 validating val_loss:0.7299 val_acc:0.8192
epoch=35 train_loss:0.4875 train_acc:0.8336 validating val_loss:0.7307 val_acc:0.8284
epoch=36 train_loss:0.4853 train_acc:0.8343 validating val_loss:0.7175 val_acc:0.8411
epoch=37 train_loss:0.4806 train_acc:0.8363 validating val_loss:0.6641 val_acc:0.8347
epoch=38 train_loss:0.4854 train_acc:0.8336 validating val_loss:0.6979 val_acc:0.8074
epoch=39 train_loss:0.4832 train_acc:0.8347 validating val_loss:0.7274 val_acc:0.8451
epoch=40 train_loss:0.4853 train_acc:0.8364 validating val_loss:0.6996 val_acc:0.8386
epoch=41 train_loss:0.4852 train_acc:0.8351 validating val_loss:0.7308 val_acc:0.8265
epoch=42 train_loss:0.4760 train_acc:0.8372 validating val_loss:0.6827 val_acc:0.8429
epoch=43 train_loss:0.4802 train_acc:0.8365 validating val_loss:0.6911 val_acc:0.8478
epoch=44 train_loss:0.4737 train_acc:0.8385 validating val_loss:0.7380 val_acc:0.8334
epoch=45 train_loss:0.4802 train_acc:0.8359 validating val_loss:0.7036 val_acc:0.8253
epoch=46 train_loss:0.4734 train_acc:0.8388 validating val_loss:0.6995 val_acc:0.8479
epoch=47 train_loss:0.4761 train_acc:0.8383 validating val_loss:0.6915 val_acc:0.8450
epoch=48 train_loss:0.4696 train_acc:0.8408 validating val_loss:0.6553 val_acc:0.8496
epoch=49 train_loss:0.4747 train_acc:0.8396 validating val_loss:0.6987 val_acc:0.8405
epoch=50 train_loss:0.4756 train_acc:0.8371 validating val_loss:0.7250 val_acc:0.8339
epoch=51 train_loss:0.4807 train_acc:0.8378 validating val_loss:0.6905 val_acc:0.8315
epoch=52 train_loss:0.4726 train_acc:0.8409 validating val_loss:0.6337 val_acc:0.8560
epoch=53 train_loss:0.4807 train_acc:0.8377 validating val_loss:0.6701 val_acc:0.8465
epoch=54 train_loss:0.4759 train_acc:0.8390 validating val_loss:0.7153 val_acc:0.8335
epoch=55 train_loss:0.4768 train_acc:0.8391 validating val_loss:0.6663 val_acc:0.8471
epoch=56 train_loss:0.4802 train_acc:0.8369 validating val_loss:0.6797 val_acc:0.8517
epoch=57 train_loss:0.4800 train_acc:0.8384 validating val_loss:0.6502 val_acc:0.8432
epoch=58 train_loss:0.4769 train_acc:0.8393 validating val_loss:0.6731 val_acc:0.8507
epoch=59 train_loss:0.4759 train_acc:0.8392 validating val_loss:0.6677 val_acc:0.8544
epoch=60 train_loss:0.4845 train_acc:0.8375 validating val_loss:0.6828 val_acc:0.8414
epoch=61 train_loss:0.4769 train_acc:0.8399 validating val_loss:0.6181 val_acc:0.8495
epoch=62 train_loss:0.4765 train_acc:0.8400 validating val_loss:0.6818 val_acc:0.8385
epoch=63 train_loss:0.4737 train_acc:0.8406 validating val_loss:0.6252 val_acc:0.8468
epoch=64 train_loss:0.4806 train_acc:0.8391 validating val_loss:0.6636 val_acc:0.8479
epoch=65 train_loss:0.4790 train_acc:0.8381 validating val_loss:0.6161 val_acc:0.8495
epoch=66 train_loss:0.4723 train_acc:0.8405 validating val_loss:0.6596 val_acc:0.8480
epoch=67 train_loss:0.4833 train_acc:0.8354 validating val_loss:0.6422 val_acc:0.8509
epoch=68 train_loss:0.4782 train_acc:0.8403 validating val_loss:0.6614 val_acc:0.8318
epoch=69 train_loss:0.4875 train_acc:0.8357 validating val_loss:0.6576 val_acc:0.8484
epoch=70 train_loss:0.4778 train_acc:0.8411 validating val_loss:0.6543 val_acc:0.8426
epoch=71 train_loss:0.4892 train_acc:0.8362 validating val_loss:0.6523 val_acc:0.8416
epoch=72 train_loss:0.4871 train_acc:0.8355 validating val_loss:0.6845 val_acc:0.8318
epoch=73 train_loss:0.4894 train_acc:0.8340 validating val_loss:0.6427 val_acc:0.8359
epoch=74 train_loss:0.4786 train_acc:0.8394 validating val_loss:0.6347 val_acc:0.8590
epoch=75 train_loss:0.4906 train_acc:0.8339 validating val_loss:0.7129 val_acc:0.8356
epoch=76 train_loss:0.4897 train_acc:0.8354 validating val_loss:0.6646 val_acc:0.8463
Epoch    76: reducing learning rate of group 0 to 1.0000e-03.
epoch=77 train_loss:0.4111 train_acc:0.8620 validating val_loss:0.5623 val_acc:0.8684
epoch=78 train_loss:0.3725 train_acc:0.8725 validating val_loss:0.5492 val_acc:0.8684
epoch=79 train_loss:0.3588 train_acc:0.8779 validating val_loss:0.5189 val_acc:0.8764
epoch=80 train_loss:0.3511 train_acc:0.8800 validating val_loss:0.5228 val_acc:0.8746
epoch=81 train_loss:0.3446 train_acc:0.8829 validating val_loss:0.5213 val_acc:0.8764
epoch=82 train_loss:0.3339 train_acc:0.8865 validating val_loss:0.5161 val_acc:0.8779
epoch=83 train_loss:0.3288 train_acc:0.8878 validating val_loss:0.5079 val_acc:0.8781
epoch=84 train_loss:0.3206 train_acc:0.8899 validating val_loss:0.5102 val_acc:0.8798
epoch=85 train_loss:0.3191 train_acc:0.8914 validating val_loss:0.4911 val_acc:0.8816
epoch=86 train_loss:0.3145 train_acc:0.8920 validating val_loss:0.4991 val_acc:0.8841
epoch=87 train_loss:0.3121 train_acc:0.8936 validating val_loss:0.4931 val_acc:0.8811
epoch=88 train_loss:0.3055 train_acc:0.8970 validating val_loss:0.4898 val_acc:0.8799
epoch=89 train_loss:0.3075 train_acc:0.8939 validating val_loss:0.4911 val_acc:0.8845
epoch=90 train_loss:0.3046 train_acc:0.8958 validating val_loss:0.4931 val_acc:0.8812
epoch=91 train_loss:0.3032 train_acc:0.8962 validating val_loss:0.4888 val_acc:0.8854
epoch=92 train_loss:0.3002 train_acc:0.8979 validating val_loss:0.4920 val_acc:0.8842
epoch=93 train_loss:0.2949 train_acc:0.8984 validating val_loss:0.4931 val_acc:0.8774
epoch=94 train_loss:0.2926 train_acc:0.8996 validating val_loss:0.4868 val_acc:0.8841
epoch=95 train_loss:0.2899 train_acc:0.9003 validating val_loss:0.4828 val_acc:0.8835
epoch=96 train_loss:0.2862 train_acc:0.9022 validating val_loss:0.4760 val_acc:0.8826
epoch=97 train_loss:0.2830 train_acc:0.9034 validating val_loss:0.4730 val_acc:0.8858
epoch=98 train_loss:0.2848 train_acc:0.9028 validating val_loss:0.4837 val_acc:0.8831
epoch=99 train_loss:0.2798 train_acc:0.9026 validating val_loss:0.4702 val_acc:0.8893
epoch=100 train_loss:0.2829 train_acc:0.9034 validating val_loss:0.4825 val_acc:0.8861
epoch=101 train_loss:0.2814 train_acc:0.9021 validating val_loss:0.4815 val_acc:0.8843
epoch=102 train_loss:0.2777 train_acc:0.9049 validating val_loss:0.4724 val_acc:0.8872
epoch=103 train_loss:0.2712 train_acc:0.9077 validating val_loss:0.4614 val_acc:0.8898
epoch=104 train_loss:0.2713 train_acc:0.9062 validating val_loss:0.4702 val_acc:0.8866
epoch=105 train_loss:0.2709 train_acc:0.9068 validating val_loss:0.4657 val_acc:0.8888
epoch=106 train_loss:0.2690 train_acc:0.9067 validating val_loss:0.4672 val_acc:0.8898
epoch=107 train_loss:0.2718 train_acc:0.9079 validating val_loss:0.4709 val_acc:0.8903
epoch=108 train_loss:0.2654 train_acc:0.9094 validating val_loss:0.4588 val_acc:0.8866
epoch=109 train_loss:0.2643 train_acc:0.9070 validating val_loss:0.4588 val_acc:0.8867
epoch=110 train_loss:0.2597 train_acc:0.9098 validating val_loss:0.4593 val_acc:0.8904
epoch=111 train_loss:0.2636 train_acc:0.9085 validating val_loss:0.4672 val_acc:0.8886
epoch=112 train_loss:0.2618 train_acc:0.9096 validating val_loss:0.4654 val_acc:0.8878
epoch=113 train_loss:0.2584 train_acc:0.9106 validating val_loss:0.4599 val_acc:0.8866
epoch=114 train_loss:0.2586 train_acc:0.9104 validating val_loss:0.4557 val_acc:0.8912
epoch=115 train_loss:0.2557 train_acc:0.9113 validating val_loss:0.4553 val_acc:0.8895
epoch=116 train_loss:0.2598 train_acc:0.9109 validating val_loss:0.4574 val_acc:0.8909
epoch=117 train_loss:0.2548 train_acc:0.9116 validating val_loss:0.4623 val_acc:0.8866
epoch=118 train_loss:0.2572 train_acc:0.9114 validating val_loss:0.4642 val_acc:0.8922
epoch=119 train_loss:0.2494 train_acc:0.9136 validating val_loss:0.4601 val_acc:0.8890
epoch=120 train_loss:0.2534 train_acc:0.9146 validating val_loss:0.4587 val_acc:0.8928
epoch=121 train_loss:0.2503 train_acc:0.9143 validating val_loss:0.4569 val_acc:0.8882
epoch=122 train_loss:0.2478 train_acc:0.9133 validating val_loss:0.4541 val_acc:0.8924
epoch=123 train_loss:0.2475 train_acc:0.9149 validating val_loss:0.4550 val_acc:0.8962
epoch=124 train_loss:0.2456 train_acc:0.9144 validating val_loss:0.4483 val_acc:0.8916
epoch=125 train_loss:0.2456 train_acc:0.9138 validating val_loss:0.4565 val_acc:0.8900
epoch=126 train_loss:0.2412 train_acc:0.9166 validating val_loss:0.4559 val_acc:0.8884
epoch=127 train_loss:0.2474 train_acc:0.9156 validating val_loss:0.4512 val_acc:0.8904
epoch=128 train_loss:0.2374 train_acc:0.9171 validating val_loss:0.4434 val_acc:0.8925
epoch=129 train_loss:0.2400 train_acc:0.9169 validating val_loss:0.4403 val_acc:0.8939
epoch=130 train_loss:0.2413 train_acc:0.9167 validating val_loss:0.4450 val_acc:0.8916
epoch=131 train_loss:0.2375 train_acc:0.9178 validating val_loss:0.4478 val_acc:0.8862
epoch=132 train_loss:0.2384 train_acc:0.9173 validating val_loss:0.4406 val_acc:0.8880
epoch=133 train_loss:0.2338 train_acc:0.9181 validating val_loss:0.4373 val_acc:0.8932
epoch=134 train_loss:0.2316 train_acc:0.9194 validating val_loss:0.4452 val_acc:0.8918
epoch=135 train_loss:0.2338 train_acc:0.9192 validating val_loss:0.4352 val_acc:0.8938
epoch=136 train_loss:0.2348 train_acc:0.9192 validating val_loss:0.4401 val_acc:0.8937
epoch=137 train_loss:0.2312 train_acc:0.9196 validating val_loss:0.4406 val_acc:0.8949
epoch=138 train_loss:0.2240 train_acc:0.9217 validating val_loss:0.4335 val_acc:0.8917
epoch=139 train_loss:0.2282 train_acc:0.9208 validating val_loss:0.4378 val_acc:0.8930
epoch=140 train_loss:0.2271 train_acc:0.9214 validating val_loss:0.4433 val_acc:0.8909
epoch=141 train_loss:0.2300 train_acc:0.9205 validating val_loss:0.4462 val_acc:0.8940
epoch=142 train_loss:0.2268 train_acc:0.9211 validating val_loss:0.4406 val_acc:0.8906
epoch=143 train_loss:0.2228 train_acc:0.9222 validating val_loss:0.4395 val_acc:0.8924
epoch=144 train_loss:0.2258 train_acc:0.9216 validating val_loss:0.4450 val_acc:0.8935
epoch=145 train_loss:0.2238 train_acc:0.9220 validating val_loss:0.4332 val_acc:0.8982
epoch=146 train_loss:0.2241 train_acc:0.9230 validating val_loss:0.4257 val_acc:0.8969
epoch=147 train_loss:0.2260 train_acc:0.9218 validating val_loss:0.4272 val_acc:0.8957
epoch=148 train_loss:0.2200 train_acc:0.9253 validating val_loss:0.4363 val_acc:0.8855
epoch=149 train_loss:0.2236 train_acc:0.9233 validating val_loss:0.4305 val_acc:0.8905
epoch=150 train_loss:0.2225 train_acc:0.9224 validating val_loss:0.4229 val_acc:0.8950
epoch=151 train_loss:0.2195 train_acc:0.9244 validating val_loss:0.4395 val_acc:0.8910
epoch=152 train_loss:0.2144 train_acc:0.9249 validating val_loss:0.4240 val_acc:0.8932
epoch=153 train_loss:0.2204 train_acc:0.9235 validating val_loss:0.4287 val_acc:0.8951
epoch=154 train_loss:0.2190 train_acc:0.9239 validating val_loss:0.4348 val_acc:0.8924
epoch=155 train_loss:0.2130 train_acc:0.9255 validating val_loss:0.4298 val_acc:0.8926
epoch=156 train_loss:0.2198 train_acc:0.9232 validating val_loss:0.4313 val_acc:0.8962
epoch=157 train_loss:0.2138 train_acc:0.9252 validating val_loss:0.4291 val_acc:0.8907
epoch=158 train_loss:0.2125 train_acc:0.9266 validating val_loss:0.4286 val_acc:0.8924
epoch=159 train_loss:0.2132 train_acc:0.9262 validating val_loss:0.4275 val_acc:0.8906
epoch=160 train_loss:0.2067 train_acc:0.9271 validating val_loss:0.4241 val_acc:0.8940
epoch=161 train_loss:0.2110 train_acc:0.9275 validating val_loss:0.4304 val_acc:0.8957
Epoch   161: reducing learning rate of group 0 to 1.0000e-04.
epoch=162 train_loss:0.2030 train_acc:0.9294 validating val_loss:0.4285 val_acc:0.8948
epoch=163 train_loss:0.2034 train_acc:0.9302 validating val_loss:0.4229 val_acc:0.8972
epoch=164 train_loss:0.2032 train_acc:0.9287 validating val_loss:0.4203 val_acc:0.8945
epoch=165 train_loss:0.1980 train_acc:0.9308 validating val_loss:0.4177 val_acc:0.8966
epoch=166 train_loss:0.1963 train_acc:0.9320 validating val_loss:0.4157 val_acc:0.8952
epoch=167 train_loss:0.1981 train_acc:0.9319 validating val_loss:0.4161 val_acc:0.8971
epoch=168 train_loss:0.1988 train_acc:0.9316 validating val_loss:0.4143 val_acc:0.8969
epoch=169 train_loss:0.1975 train_acc:0.9319 validating val_loss:0.4126 val_acc:0.8964
epoch=170 train_loss:0.1996 train_acc:0.9304 validating val_loss:0.4175 val_acc:0.8954
epoch=171 train_loss:0.1953 train_acc:0.9324 validating val_loss:0.4135 val_acc:0.8966
epoch=172 train_loss:0.2000 train_acc:0.9314 validating val_loss:0.4138 val_acc:0.8968
epoch=173 train_loss:0.1968 train_acc:0.9327 validating val_loss:0.4142 val_acc:0.8953
epoch=174 train_loss:0.1959 train_acc:0.9323 validating val_loss:0.4119 val_acc:0.8963
epoch=175 train_loss:0.1955 train_acc:0.9317 validating val_loss:0.4124 val_acc:0.8962
epoch=176 train_loss:0.1953 train_acc:0.9322 validating val_loss:0.4115 val_acc:0.8964
epoch=177 train_loss:0.1931 train_acc:0.9333 validating val_loss:0.4093 val_acc:0.8957
epoch=178 train_loss:0.1971 train_acc:0.9305 validating val_loss:0.4095 val_acc:0.8959
epoch=179 train_loss:0.1922 train_acc:0.9334 validating val_loss:0.4125 val_acc:0.8947
epoch=180 train_loss:0.1959 train_acc:0.9309 validating val_loss:0.4138 val_acc:0.8952
epoch=181 train_loss:0.1970 train_acc:0.9310 validating val_loss:0.4103 val_acc:0.8967
epoch=182 train_loss:0.1942 train_acc:0.9322 validating val_loss:0.4092 val_acc:0.8969
epoch=183 train_loss:0.1961 train_acc:0.9306 validating val_loss:0.4103 val_acc:0.8952
epoch=184 train_loss:0.1968 train_acc:0.9311 validating val_loss:0.4110 val_acc:0.8957
epoch=185 train_loss:0.1932 train_acc:0.9327 validating val_loss:0.4121 val_acc:0.8952
epoch=186 train_loss:0.1964 train_acc:0.9305 validating val_loss:0.4131 val_acc:0.8946
epoch=187 train_loss:0.1899 train_acc:0.9341 validating val_loss:0.4083 val_acc:0.8975
epoch=188 train_loss:0.1952 train_acc:0.9328 validating val_loss:0.4069 val_acc:0.8969
epoch=189 train_loss:0.1917 train_acc:0.9338 validating val_loss:0.4086 val_acc:0.8973
epoch=190 train_loss:0.1978 train_acc:0.9310 validating val_loss:0.4111 val_acc:0.8964
epoch=191 train_loss:0.1924 train_acc:0.9331 validating val_loss:0.4105 val_acc:0.8952
epoch=192 train_loss:0.1923 train_acc:0.9332 validating val_loss:0.4121 val_acc:0.8972
epoch=193 train_loss:0.1907 train_acc:0.9333 validating val_loss:0.4083 val_acc:0.8955
epoch=194 train_loss:0.1900 train_acc:0.9336 validating val_loss:0.4075 val_acc:0.8952
epoch=195 train_loss:0.1950 train_acc:0.9322 validating val_loss:0.4071 val_acc:0.8969
epoch=196 train_loss:0.1966 train_acc:0.9308 validating val_loss:0.4103 val_acc:0.8964
epoch=197 train_loss:0.1932 train_acc:0.9328 validating val_loss:0.4080 val_acc:0.8968
epoch=198 train_loss:0.1970 train_acc:0.9310 validating val_loss:0.4101 val_acc:0.8951
epoch=199 train_loss:0.1904 train_acc:0.9343 validating val_loss:0.4104 val_acc:0.8955
Epoch   199: reducing learning rate of group 0 to 1.0000e-05.
Finished Training
