nohup: ignoring input
1.0.1.post2
cuda is available
start training
validating val_loss:2.3027 val_acc:0.1015
epoch=1 train_loss:1.7612 train_acc:0.3249 validating val_loss:1.5154 val_acc:0.5007
epoch=2 train_loss:1.3774 train_acc:0.5053 validating val_loss:1.2783 val_acc:0.5893
epoch=3 train_loss:1.2262 train_acc:0.5673 validating val_loss:1.2147 val_acc:0.6178
epoch=4 train_loss:1.1256 train_acc:0.6033 validating val_loss:1.1180 val_acc:0.6689
epoch=5 train_loss:1.0611 train_acc:0.6283 validating val_loss:1.0304 val_acc:0.6932
epoch=6 train_loss:1.0060 train_acc:0.6472 validating val_loss:1.0490 val_acc:0.6828
epoch=7 train_loss:0.9642 train_acc:0.6637 validating val_loss:0.9130 val_acc:0.7226
epoch=8 train_loss:0.9234 train_acc:0.6801 validating val_loss:0.9707 val_acc:0.7045
epoch=9 train_loss:0.8943 train_acc:0.6909 validating val_loss:0.9103 val_acc:0.7388
epoch=10 train_loss:0.8678 train_acc:0.6976 validating val_loss:0.8525 val_acc:0.7564
epoch=11 train_loss:0.8470 train_acc:0.7085 validating val_loss:0.8477 val_acc:0.7597
epoch=12 train_loss:0.8207 train_acc:0.7161 validating val_loss:0.8527 val_acc:0.7532
epoch=13 train_loss:0.8064 train_acc:0.7196 validating val_loss:0.7792 val_acc:0.7870
epoch=14 train_loss:0.7898 train_acc:0.7281 validating val_loss:0.7924 val_acc:0.7826
epoch=15 train_loss:0.7859 train_acc:0.7312 validating val_loss:0.7712 val_acc:0.7772
epoch=16 train_loss:0.7682 train_acc:0.7368 validating val_loss:0.7913 val_acc:0.7908
epoch=17 train_loss:0.7478 train_acc:0.7434 validating val_loss:0.8778 val_acc:0.7366
epoch=18 train_loss:0.7437 train_acc:0.7457 validating val_loss:0.7896 val_acc:0.7765
epoch=19 train_loss:0.7374 train_acc:0.7479 validating val_loss:0.7906 val_acc:0.7706
epoch=20 train_loss:0.7261 train_acc:0.7516 validating val_loss:0.7865 val_acc:0.7727
epoch=21 train_loss:0.7157 train_acc:0.7540 validating val_loss:0.7371 val_acc:0.7767
epoch=22 train_loss:0.7114 train_acc:0.7562 validating val_loss:0.7481 val_acc:0.7879
epoch=23 train_loss:0.7112 train_acc:0.7548 validating val_loss:0.7289 val_acc:0.7968
epoch=24 train_loss:0.7052 train_acc:0.7572 validating val_loss:0.7078 val_acc:0.8105
epoch=25 train_loss:0.6991 train_acc:0.7604 validating val_loss:0.7298 val_acc:0.8071
epoch=26 train_loss:0.6999 train_acc:0.7613 validating val_loss:0.7178 val_acc:0.8093
epoch=27 train_loss:0.6853 train_acc:0.7648 validating val_loss:0.6960 val_acc:0.8092
epoch=28 train_loss:0.6832 train_acc:0.7677 validating val_loss:0.7403 val_acc:0.8004
epoch=29 train_loss:0.6864 train_acc:0.7669 validating val_loss:0.7304 val_acc:0.7971
epoch=30 train_loss:0.6781 train_acc:0.7691 validating val_loss:0.6969 val_acc:0.8171
epoch=31 train_loss:0.6759 train_acc:0.7690 validating val_loss:0.6666 val_acc:0.8202
epoch=32 train_loss:0.6750 train_acc:0.7697 validating val_loss:0.7063 val_acc:0.8098
epoch=33 train_loss:0.6747 train_acc:0.7688 validating val_loss:0.7093 val_acc:0.8154
epoch=34 train_loss:0.6708 train_acc:0.7708 validating val_loss:0.6540 val_acc:0.8210
epoch=35 train_loss:0.6659 train_acc:0.7743 validating val_loss:0.6939 val_acc:0.8153
epoch=36 train_loss:0.6646 train_acc:0.7743 validating val_loss:0.6917 val_acc:0.8130
epoch=37 train_loss:0.6625 train_acc:0.7763 validating val_loss:0.6517 val_acc:0.8294
epoch=38 train_loss:0.6580 train_acc:0.7767 validating val_loss:0.6826 val_acc:0.8143
epoch=39 train_loss:0.6719 train_acc:0.7721 validating val_loss:0.7021 val_acc:0.8150
epoch=40 train_loss:0.6649 train_acc:0.7734 validating val_loss:0.6719 val_acc:0.8242
epoch=41 train_loss:0.6635 train_acc:0.7747 validating val_loss:0.7028 val_acc:0.8248
epoch=42 train_loss:0.6750 train_acc:0.7727 validating val_loss:0.6845 val_acc:0.8255
epoch=43 train_loss:0.6687 train_acc:0.7727 validating val_loss:0.6894 val_acc:0.8188
epoch=44 train_loss:0.6599 train_acc:0.7750 validating val_loss:0.6891 val_acc:0.8150
epoch=45 train_loss:0.6684 train_acc:0.7762 validating val_loss:0.7206 val_acc:0.8081
epoch=46 train_loss:0.6625 train_acc:0.7774 validating val_loss:0.6744 val_acc:0.8162
epoch=47 train_loss:0.6640 train_acc:0.7756 validating val_loss:0.6685 val_acc:0.8203
epoch=48 train_loss:0.6729 train_acc:0.7726 validating val_loss:0.6704 val_acc:0.8241
Epoch    48: reducing learning rate of group 0 to 1.0000e-03.
epoch=49 train_loss:0.5780 train_acc:0.8025 validating val_loss:0.6085 val_acc:0.8434
epoch=50 train_loss:0.5546 train_acc:0.8108 validating val_loss:0.5820 val_acc:0.8474
epoch=51 train_loss:0.5425 train_acc:0.8163 validating val_loss:0.5701 val_acc:0.8506
epoch=52 train_loss:0.5378 train_acc:0.8164 validating val_loss:0.5804 val_acc:0.8469
epoch=53 train_loss:0.5287 train_acc:0.8201 validating val_loss:0.5782 val_acc:0.8459
epoch=54 train_loss:0.5212 train_acc:0.8214 validating val_loss:0.5638 val_acc:0.8450
epoch=55 train_loss:0.5149 train_acc:0.8233 validating val_loss:0.5596 val_acc:0.8546
epoch=56 train_loss:0.5137 train_acc:0.8246 validating val_loss:0.5536 val_acc:0.8560
epoch=57 train_loss:0.5100 train_acc:0.8268 validating val_loss:0.5457 val_acc:0.8524
epoch=58 train_loss:0.5077 train_acc:0.8250 validating val_loss:0.5447 val_acc:0.8558
epoch=59 train_loss:0.4961 train_acc:0.8291 validating val_loss:0.5380 val_acc:0.8578
epoch=60 train_loss:0.5038 train_acc:0.8252 validating val_loss:0.5381 val_acc:0.8563
epoch=61 train_loss:0.4966 train_acc:0.8297 validating val_loss:0.5502 val_acc:0.8558
epoch=62 train_loss:0.4957 train_acc:0.8324 validating val_loss:0.5368 val_acc:0.8583
epoch=63 train_loss:0.4962 train_acc:0.8304 validating val_loss:0.5372 val_acc:0.8575
epoch=64 train_loss:0.4919 train_acc:0.8318 validating val_loss:0.5336 val_acc:0.8563
epoch=65 train_loss:0.4893 train_acc:0.8331 validating val_loss:0.5245 val_acc:0.8616
epoch=66 train_loss:0.4836 train_acc:0.8345 validating val_loss:0.5171 val_acc:0.8622
epoch=67 train_loss:0.4809 train_acc:0.8356 validating val_loss:0.5147 val_acc:0.8628
epoch=68 train_loss:0.4829 train_acc:0.8353 validating val_loss:0.5251 val_acc:0.8575
epoch=69 train_loss:0.4784 train_acc:0.8369 validating val_loss:0.5038 val_acc:0.8650
epoch=70 train_loss:0.4737 train_acc:0.8354 validating val_loss:0.5041 val_acc:0.8629
epoch=71 train_loss:0.4773 train_acc:0.8376 validating val_loss:0.5080 val_acc:0.8652
epoch=72 train_loss:0.4718 train_acc:0.8386 validating val_loss:0.5113 val_acc:0.8620
epoch=73 train_loss:0.4768 train_acc:0.8368 validating val_loss:0.5126 val_acc:0.8677
epoch=74 train_loss:0.4701 train_acc:0.8386 validating val_loss:0.5042 val_acc:0.8675
epoch=75 train_loss:0.4687 train_acc:0.8409 validating val_loss:0.4948 val_acc:0.8672
epoch=76 train_loss:0.4694 train_acc:0.8400 validating val_loss:0.4953 val_acc:0.8656
epoch=77 train_loss:0.4647 train_acc:0.8415 validating val_loss:0.4998 val_acc:0.8663
epoch=78 train_loss:0.4635 train_acc:0.8419 validating val_loss:0.4975 val_acc:0.8671
epoch=79 train_loss:0.4593 train_acc:0.8427 validating val_loss:0.4832 val_acc:0.8680
epoch=80 train_loss:0.4626 train_acc:0.8428 validating val_loss:0.4911 val_acc:0.8682
epoch=81 train_loss:0.4580 train_acc:0.8431 validating val_loss:0.4862 val_acc:0.8690
epoch=82 train_loss:0.4564 train_acc:0.8442 validating val_loss:0.4811 val_acc:0.8704
epoch=83 train_loss:0.4572 train_acc:0.8435 validating val_loss:0.4786 val_acc:0.8683
epoch=84 train_loss:0.4527 train_acc:0.8432 validating val_loss:0.4838 val_acc:0.8710
epoch=85 train_loss:0.4511 train_acc:0.8463 validating val_loss:0.4930 val_acc:0.8650
epoch=86 train_loss:0.4449 train_acc:0.8466 validating val_loss:0.4806 val_acc:0.8671
epoch=87 train_loss:0.4521 train_acc:0.8456 validating val_loss:0.4867 val_acc:0.8651
epoch=88 train_loss:0.4451 train_acc:0.8458 validating val_loss:0.4661 val_acc:0.8716
epoch=89 train_loss:0.4424 train_acc:0.8486 validating val_loss:0.4697 val_acc:0.8701
epoch=90 train_loss:0.4401 train_acc:0.8497 validating val_loss:0.4739 val_acc:0.8659
epoch=91 train_loss:0.4423 train_acc:0.8487 validating val_loss:0.4717 val_acc:0.8655
epoch=92 train_loss:0.4467 train_acc:0.8465 validating val_loss:0.4703 val_acc:0.8714
epoch=93 train_loss:0.4454 train_acc:0.8481 validating val_loss:0.4655 val_acc:0.8725
epoch=94 train_loss:0.4441 train_acc:0.8469 validating val_loss:0.4709 val_acc:0.8725
epoch=95 train_loss:0.4400 train_acc:0.8474 validating val_loss:0.4670 val_acc:0.8716
epoch=96 train_loss:0.4399 train_acc:0.8497 validating val_loss:0.4596 val_acc:0.8773
epoch=97 train_loss:0.4362 train_acc:0.8498 validating val_loss:0.4640 val_acc:0.8708
epoch=98 train_loss:0.4341 train_acc:0.8523 validating val_loss:0.4612 val_acc:0.8734
epoch=99 train_loss:0.4356 train_acc:0.8499 validating val_loss:0.4637 val_acc:0.8710
epoch=100 train_loss:0.4392 train_acc:0.8501 validating val_loss:0.4555 val_acc:0.8776
epoch=101 train_loss:0.4333 train_acc:0.8517 validating val_loss:0.4547 val_acc:0.8737
epoch=102 train_loss:0.4320 train_acc:0.8516 validating val_loss:0.4441 val_acc:0.8793
epoch=103 train_loss:0.4303 train_acc:0.8510 validating val_loss:0.4575 val_acc:0.8732
epoch=104 train_loss:0.4286 train_acc:0.8518 validating val_loss:0.4462 val_acc:0.8753
epoch=105 train_loss:0.4353 train_acc:0.8505 validating val_loss:0.4614 val_acc:0.8671
epoch=106 train_loss:0.4285 train_acc:0.8519 validating val_loss:0.4592 val_acc:0.8688
epoch=107 train_loss:0.4255 train_acc:0.8543 validating val_loss:0.4483 val_acc:0.8740
epoch=108 train_loss:0.4241 train_acc:0.8558 validating val_loss:0.4505 val_acc:0.8756
epoch=109 train_loss:0.4274 train_acc:0.8539 validating val_loss:0.4478 val_acc:0.8729
epoch=110 train_loss:0.4246 train_acc:0.8531 validating val_loss:0.4518 val_acc:0.8737
epoch=111 train_loss:0.4244 train_acc:0.8532 validating val_loss:0.4575 val_acc:0.8751
epoch=112 train_loss:0.4254 train_acc:0.8543 validating val_loss:0.4462 val_acc:0.8718
epoch=113 train_loss:0.4189 train_acc:0.8567 validating val_loss:0.4521 val_acc:0.8739
Epoch   113: reducing learning rate of group 0 to 1.0000e-04.
epoch=114 train_loss:0.4191 train_acc:0.8555 validating val_loss:0.4388 val_acc:0.8785
epoch=115 train_loss:0.4071 train_acc:0.8600 validating val_loss:0.4329 val_acc:0.8790
epoch=116 train_loss:0.4126 train_acc:0.8572 validating val_loss:0.4372 val_acc:0.8775
epoch=117 train_loss:0.4050 train_acc:0.8613 validating val_loss:0.4342 val_acc:0.8798
epoch=118 train_loss:0.4127 train_acc:0.8567 validating val_loss:0.4385 val_acc:0.8786
epoch=119 train_loss:0.4057 train_acc:0.8602 validating val_loss:0.4315 val_acc:0.8788
epoch=120 train_loss:0.4051 train_acc:0.8614 validating val_loss:0.4277 val_acc:0.8801
epoch=121 train_loss:0.4029 train_acc:0.8605 validating val_loss:0.4332 val_acc:0.8797
epoch=122 train_loss:0.4031 train_acc:0.8606 validating val_loss:0.4316 val_acc:0.8790
epoch=123 train_loss:0.4031 train_acc:0.8613 validating val_loss:0.4338 val_acc:0.8797
epoch=124 train_loss:0.4054 train_acc:0.8602 validating val_loss:0.4309 val_acc:0.8796
epoch=125 train_loss:0.4068 train_acc:0.8605 validating val_loss:0.4327 val_acc:0.8794
epoch=126 train_loss:0.4061 train_acc:0.8611 validating val_loss:0.4314 val_acc:0.8806
epoch=127 train_loss:0.4055 train_acc:0.8600 validating val_loss:0.4312 val_acc:0.8795
epoch=128 train_loss:0.4022 train_acc:0.8625 validating val_loss:0.4307 val_acc:0.8796
epoch=129 train_loss:0.4018 train_acc:0.8616 validating val_loss:0.4281 val_acc:0.8808
epoch=130 train_loss:0.4046 train_acc:0.8595 validating val_loss:0.4288 val_acc:0.8809
epoch=131 train_loss:0.4051 train_acc:0.8605 validating val_loss:0.4289 val_acc:0.8797
Epoch   131: reducing learning rate of group 0 to 1.0000e-05.
epoch=132 train_loss:0.4046 train_acc:0.8615 validating val_loss:0.4304 val_acc:0.8809
epoch=133 train_loss:0.4016 train_acc:0.8617 validating val_loss:0.4316 val_acc:0.8808
epoch=134 train_loss:0.4058 train_acc:0.8601 validating val_loss:0.4294 val_acc:0.8807
epoch=135 train_loss:0.4018 train_acc:0.8623 validating val_loss:0.4306 val_acc:0.8811
epoch=136 train_loss:0.4023 train_acc:0.8617 validating val_loss:0.4285 val_acc:0.8807
epoch=137 train_loss:0.4072 train_acc:0.8600 validating val_loss:0.4275 val_acc:0.8805
epoch=138 train_loss:0.4063 train_acc:0.8593 validating val_loss:0.4284 val_acc:0.8796
epoch=139 train_loss:0.3999 train_acc:0.8617 validating val_loss:0.4270 val_acc:0.8814
epoch=140 train_loss:0.4015 train_acc:0.8631 validating val_loss:0.4294 val_acc:0.8816
epoch=141 train_loss:0.3981 train_acc:0.8626 validating val_loss:0.4289 val_acc:0.8796
epoch=142 train_loss:0.4039 train_acc:0.8604 validating val_loss:0.4309 val_acc:0.8793
epoch=143 train_loss:0.4023 train_acc:0.8620 validating val_loss:0.4298 val_acc:0.8795
epoch=144 train_loss:0.4064 train_acc:0.8604 validating val_loss:0.4281 val_acc:0.8800
epoch=145 train_loss:0.4063 train_acc:0.8598 validating val_loss:0.4306 val_acc:0.8805
epoch=146 train_loss:0.4026 train_acc:0.8626 validating val_loss:0.4279 val_acc:0.8799
epoch=147 train_loss:0.3991 train_acc:0.8622 validating val_loss:0.4276 val_acc:0.8805
epoch=148 train_loss:0.4026 train_acc:0.8624 validating val_loss:0.4264 val_acc:0.8801
epoch=149 train_loss:0.4017 train_acc:0.8601 validating val_loss:0.4278 val_acc:0.8807
epoch=150 train_loss:0.4056 train_acc:0.8586 validating val_loss:0.4307 val_acc:0.8801
epoch=151 train_loss:0.4041 train_acc:0.8606 validating val_loss:0.4274 val_acc:0.8809
epoch=152 train_loss:0.3989 train_acc:0.8619 validating val_loss:0.4278 val_acc:0.8808
epoch=153 train_loss:0.3993 train_acc:0.8630 validating val_loss:0.4278 val_acc:0.8808
epoch=154 train_loss:0.4010 train_acc:0.8614 validating val_loss:0.4287 val_acc:0.8818
epoch=155 train_loss:0.4011 train_acc:0.8624 validating val_loss:0.4304 val_acc:0.8804
epoch=156 train_loss:0.4006 train_acc:0.8635 validating val_loss:0.4311 val_acc:0.8805
epoch=157 train_loss:0.3997 train_acc:0.8625 validating val_loss:0.4286 val_acc:0.8811
epoch=158 train_loss:0.4033 train_acc:0.8600 validating val_loss:0.4294 val_acc:0.8810
epoch=159 train_loss:0.4025 train_acc:0.8613 validating val_loss:0.4270 val_acc:0.8813
Epoch   159: reducing learning rate of group 0 to 1.0000e-06.
epoch=160 train_loss:0.4002 train_acc:0.8633 validating val_loss:0.4282 val_acc:0.8803
epoch=161 train_loss:0.4011 train_acc:0.8607 validating val_loss:0.4282 val_acc:0.8810
epoch=162 train_loss:0.4013 train_acc:0.8623 validating val_loss:0.4287 val_acc:0.8811
epoch=163 train_loss:0.4085 train_acc:0.8596 validating val_loss:0.4285 val_acc:0.8806
epoch=164 train_loss:0.4040 train_acc:0.8606 validating val_loss:0.4286 val_acc:0.8799
epoch=165 train_loss:0.4017 train_acc:0.8618 validating val_loss:0.4254 val_acc:0.8811
epoch=166 train_loss:0.4011 train_acc:0.8631 validating val_loss:0.4272 val_acc:0.8805
epoch=167 train_loss:0.3996 train_acc:0.8603 validating val_loss:0.4301 val_acc:0.8806
epoch=168 train_loss:0.3970 train_acc:0.8633 validating val_loss:0.4270 val_acc:0.8812
epoch=169 train_loss:0.4010 train_acc:0.8618 validating val_loss:0.4298 val_acc:0.8804
epoch=170 train_loss:0.4004 train_acc:0.8616 validating val_loss:0.4286 val_acc:0.8817
epoch=171 train_loss:0.4024 train_acc:0.8608 validating val_loss:0.4301 val_acc:0.8808
epoch=172 train_loss:0.4060 train_acc:0.8618 validating val_loss:0.4287 val_acc:0.8806
epoch=173 train_loss:0.3973 train_acc:0.8632 validating val_loss:0.4282 val_acc:0.8810
epoch=174 train_loss:0.3981 train_acc:0.8627 validating val_loss:0.4279 val_acc:0.8808
epoch=175 train_loss:0.3984 train_acc:0.8621 validating val_loss:0.4292 val_acc:0.8806
epoch=176 train_loss:0.4013 train_acc:0.8619 validating val_loss:0.4280 val_acc:0.8809
Epoch   176: reducing learning rate of group 0 to 1.0000e-07.
epoch=177 train_loss:0.4000 train_acc:0.8630 validating val_loss:0.4291 val_acc:0.8812
epoch=178 train_loss:0.4013 train_acc:0.8620 validating val_loss:0.4267 val_acc:0.8811
epoch=179 train_loss:0.4017 train_acc:0.8621 validating val_loss:0.4304 val_acc:0.8806
epoch=180 train_loss:0.4066 train_acc:0.8600 validating val_loss:0.4298 val_acc:0.8809
epoch=181 train_loss:0.4016 train_acc:0.8601 validating val_loss:0.4259 val_acc:0.8807
epoch=182 train_loss:0.4017 train_acc:0.8608 validating val_loss:0.4265 val_acc:0.8807
epoch=183 train_loss:0.4047 train_acc:0.8610 validating val_loss:0.4295 val_acc:0.8810
epoch=184 train_loss:0.4048 train_acc:0.8614 validating val_loss:0.4274 val_acc:0.8815
epoch=185 train_loss:0.4015 train_acc:0.8629 validating val_loss:0.4282 val_acc:0.8820
epoch=186 train_loss:0.4030 train_acc:0.8615 validating val_loss:0.4286 val_acc:0.8801
epoch=187 train_loss:0.4025 train_acc:0.8617 validating val_loss:0.4285 val_acc:0.8799
Epoch   187: reducing learning rate of group 0 to 1.0000e-08.
epoch=188 train_loss:0.4038 train_acc:0.8598 validating val_loss:0.4281 val_acc:0.8816
epoch=189 train_loss:0.4038 train_acc:0.8605 validating val_loss:0.4331 val_acc:0.8804
epoch=190 train_loss:0.3999 train_acc:0.8634 validating val_loss:0.4283 val_acc:0.8814
epoch=191 train_loss:0.4002 train_acc:0.8634 validating val_loss:0.4313 val_acc:0.8807
epoch=192 train_loss:0.3994 train_acc:0.8625 validating val_loss:0.4270 val_acc:0.8814
epoch=193 train_loss:0.4017 train_acc:0.8618 validating val_loss:0.4278 val_acc:0.8812
epoch=194 train_loss:0.3998 train_acc:0.8612 validating val_loss:0.4276 val_acc:0.8809
epoch=195 train_loss:0.4057 train_acc:0.8615 validating val_loss:0.4274 val_acc:0.8814
epoch=196 train_loss:0.4044 train_acc:0.8586 validating val_loss:0.4259 val_acc:0.8821
epoch=197 train_loss:0.4024 train_acc:0.8609 validating val_loss:0.4304 val_acc:0.8807
epoch=198 train_loss:0.4009 train_acc:0.8611 validating val_loss:0.4295 val_acc:0.8799
epoch=199 train_loss:0.4009 train_acc:0.8631 validating val_loss:0.4275 val_acc:0.8824
Finished Training
