SGD lr=1.00e-02~ weight_decay=1.00e-05
Dropout=0.5
nohup: ignoring input
1.0.1.post2
cuda is available
start training
validating val_loss:2.3039 val_acc:0.1000
epoch=1 train_loss:1.6488 train_acc:0.3770 validating val_loss:1.4075 val_acc:0.5081
epoch=2 train_loss:1.2279 train_acc:0.5566 validating val_loss:1.1959 val_acc:0.5868
epoch=3 train_loss:1.0427 train_acc:0.6308 validating val_loss:1.0969 val_acc:0.6197
epoch=4 train_loss:0.9471 train_acc:0.6669 validating val_loss:0.9520 val_acc:0.6725
epoch=5 train_loss:0.8589 train_acc:0.6959 validating val_loss:0.8440 val_acc:0.7168
epoch=6 train_loss:0.7937 train_acc:0.7234 validating val_loss:0.8403 val_acc:0.7160
epoch=7 train_loss:0.7481 train_acc:0.7382 validating val_loss:0.8128 val_acc:0.7312
epoch=8 train_loss:0.7051 train_acc:0.7550 validating val_loss:0.8303 val_acc:0.7147
epoch=9 train_loss:0.6728 train_acc:0.7683 validating val_loss:0.7495 val_acc:0.7451
epoch=10 train_loss:0.6496 train_acc:0.7752 validating val_loss:0.6827 val_acc:0.7746
epoch=11 train_loss:0.6251 train_acc:0.7845 validating val_loss:0.6804 val_acc:0.7729
epoch=12 train_loss:0.6018 train_acc:0.7918 validating val_loss:0.6506 val_acc:0.7837
epoch=13 train_loss:0.5880 train_acc:0.7973 validating val_loss:0.5827 val_acc:0.8039
epoch=14 train_loss:0.5695 train_acc:0.8051 validating val_loss:0.6231 val_acc:0.7905
epoch=15 train_loss:0.5573 train_acc:0.8077 validating val_loss:0.5863 val_acc:0.7975
epoch=16 train_loss:0.5425 train_acc:0.8124 validating val_loss:0.5871 val_acc:0.8049
epoch=17 train_loss:0.5264 train_acc:0.8185 validating val_loss:0.6193 val_acc:0.7948
epoch=18 train_loss:0.5186 train_acc:0.8212 validating val_loss:0.5693 val_acc:0.8150
epoch=19 train_loss:0.5179 train_acc:0.8217 validating val_loss:0.5823 val_acc:0.8049
epoch=20 train_loss:0.5035 train_acc:0.8274 validating val_loss:0.5566 val_acc:0.8162
epoch=21 train_loss:0.4952 train_acc:0.8294 validating val_loss:0.5501 val_acc:0.8171
epoch=22 train_loss:0.4927 train_acc:0.8307 validating val_loss:0.5908 val_acc:0.8012
epoch=23 train_loss:0.4903 train_acc:0.8297 validating val_loss:0.5478 val_acc:0.8214
epoch=24 train_loss:0.4921 train_acc:0.8299 validating val_loss:0.5845 val_acc:0.8047
epoch=25 train_loss:0.4806 train_acc:0.8344 validating val_loss:0.5480 val_acc:0.8191
epoch=26 train_loss:0.4776 train_acc:0.8365 validating val_loss:0.5592 val_acc:0.8116
epoch=27 train_loss:0.4733 train_acc:0.8374 validating val_loss:0.5703 val_acc:0.8111
epoch=28 train_loss:0.4760 train_acc:0.8343 validating val_loss:0.5385 val_acc:0.8239
epoch=29 train_loss:0.4629 train_acc:0.8418 validating val_loss:0.5202 val_acc:0.8286
epoch=30 train_loss:0.4670 train_acc:0.8408 validating val_loss:0.5368 val_acc:0.8255
epoch=31 train_loss:0.4584 train_acc:0.8424 validating val_loss:0.5271 val_acc:0.8252
epoch=32 train_loss:0.4621 train_acc:0.8417 validating val_loss:0.5273 val_acc:0.8245
epoch=33 train_loss:0.4649 train_acc:0.8404 validating val_loss:0.5215 val_acc:0.8298
epoch=34 train_loss:0.4668 train_acc:0.8388 validating val_loss:0.5427 val_acc:0.8222
epoch=35 train_loss:0.4699 train_acc:0.8391 validating val_loss:0.5359 val_acc:0.8282
epoch=36 train_loss:0.4669 train_acc:0.8387 validating val_loss:0.5490 val_acc:0.8165
epoch=37 train_loss:0.4605 train_acc:0.8417 validating val_loss:0.6067 val_acc:0.8001
epoch=38 train_loss:0.4668 train_acc:0.8390 validating val_loss:0.5352 val_acc:0.8203
epoch=39 train_loss:0.4616 train_acc:0.8421 validating val_loss:0.5169 val_acc:0.8317
epoch=40 train_loss:0.4709 train_acc:0.8394 validating val_loss:0.5273 val_acc:0.8243
epoch=41 train_loss:0.4729 train_acc:0.8393 validating val_loss:0.5764 val_acc:0.8147
epoch=42 train_loss:0.4794 train_acc:0.8364 validating val_loss:0.5234 val_acc:0.8294
epoch=43 train_loss:0.4790 train_acc:0.8374 validating val_loss:0.5441 val_acc:0.8171
epoch=44 train_loss:0.4851 train_acc:0.8351 validating val_loss:0.5676 val_acc:0.8120
epoch=45 train_loss:0.4938 train_acc:0.8328 validating val_loss:0.5704 val_acc:0.8172
epoch=46 train_loss:0.4906 train_acc:0.8314 validating val_loss:0.5201 val_acc:0.8306
epoch=47 train_loss:0.4889 train_acc:0.8326 validating val_loss:0.5190 val_acc:0.8292
epoch=48 train_loss:0.5037 train_acc:0.8288 validating val_loss:0.5717 val_acc:0.8127
epoch=49 train_loss:0.4994 train_acc:0.8304 validating val_loss:0.5767 val_acc:0.8104
epoch=50 train_loss:0.5057 train_acc:0.8275 validating val_loss:0.5493 val_acc:0.8179
Epoch    50: reducing learning rate of group 0 to 1.0000e-03.
epoch=51 train_loss:0.4117 train_acc:0.8591 validating val_loss:0.4659 val_acc:0.8463
epoch=52 train_loss:0.3611 train_acc:0.8752 validating val_loss:0.4495 val_acc:0.8516
epoch=53 train_loss:0.3467 train_acc:0.8806 validating val_loss:0.4434 val_acc:0.8518
epoch=54 train_loss:0.3394 train_acc:0.8812 validating val_loss:0.4404 val_acc:0.8543
epoch=55 train_loss:0.3253 train_acc:0.8879 validating val_loss:0.4380 val_acc:0.8544
epoch=56 train_loss:0.3138 train_acc:0.8918 validating val_loss:0.4344 val_acc:0.8571
epoch=57 train_loss:0.3095 train_acc:0.8917 validating val_loss:0.4480 val_acc:0.8530
epoch=58 train_loss:0.3065 train_acc:0.8929 validating val_loss:0.4256 val_acc:0.8568
epoch=59 train_loss:0.2981 train_acc:0.8958 validating val_loss:0.4252 val_acc:0.8600
epoch=60 train_loss:0.2910 train_acc:0.8981 validating val_loss:0.4177 val_acc:0.8635
epoch=61 train_loss:0.2851 train_acc:0.8999 validating val_loss:0.4248 val_acc:0.8612
epoch=62 train_loss:0.2813 train_acc:0.9020 validating val_loss:0.4169 val_acc:0.8629
epoch=63 train_loss:0.2790 train_acc:0.9021 validating val_loss:0.4237 val_acc:0.8610
epoch=64 train_loss:0.2775 train_acc:0.9038 validating val_loss:0.4177 val_acc:0.8651
epoch=65 train_loss:0.2670 train_acc:0.9070 validating val_loss:0.4162 val_acc:0.8624
epoch=66 train_loss:0.2669 train_acc:0.9072 validating val_loss:0.4162 val_acc:0.8660
epoch=67 train_loss:0.2704 train_acc:0.9069 validating val_loss:0.4186 val_acc:0.8645
epoch=68 train_loss:0.2617 train_acc:0.9089 validating val_loss:0.4195 val_acc:0.8635
epoch=69 train_loss:0.2605 train_acc:0.9088 validating val_loss:0.4226 val_acc:0.8652
epoch=70 train_loss:0.2557 train_acc:0.9107 validating val_loss:0.4243 val_acc:0.8605
epoch=71 train_loss:0.2541 train_acc:0.9121 validating val_loss:0.4175 val_acc:0.8648
epoch=72 train_loss:0.2500 train_acc:0.9130 validating val_loss:0.4197 val_acc:0.8641
epoch=73 train_loss:0.2457 train_acc:0.9147 validating val_loss:0.4135 val_acc:0.8655
epoch=74 train_loss:0.2454 train_acc:0.9138 validating val_loss:0.4118 val_acc:0.8657
epoch=75 train_loss:0.2451 train_acc:0.9143 validating val_loss:0.4157 val_acc:0.8647
epoch=76 train_loss:0.2400 train_acc:0.9158 validating val_loss:0.4135 val_acc:0.8654
epoch=77 train_loss:0.2389 train_acc:0.9170 validating val_loss:0.4135 val_acc:0.8669
epoch=78 train_loss:0.2334 train_acc:0.9186 validating val_loss:0.4189 val_acc:0.8640
epoch=79 train_loss:0.2328 train_acc:0.9179 validating val_loss:0.4185 val_acc:0.8650
epoch=80 train_loss:0.2289 train_acc:0.9184 validating val_loss:0.4127 val_acc:0.8700
epoch=81 train_loss:0.2291 train_acc:0.9196 validating val_loss:0.4160 val_acc:0.8684
epoch=82 train_loss:0.2277 train_acc:0.9203 validating val_loss:0.4193 val_acc:0.8642
epoch=83 train_loss:0.2275 train_acc:0.9196 validating val_loss:0.4194 val_acc:0.8654
epoch=84 train_loss:0.2239 train_acc:0.9217 validating val_loss:0.4064 val_acc:0.8669
epoch=85 train_loss:0.2224 train_acc:0.9219 validating val_loss:0.4124 val_acc:0.8689
epoch=86 train_loss:0.2197 train_acc:0.9234 validating val_loss:0.4202 val_acc:0.8660
epoch=87 train_loss:0.2219 train_acc:0.9225 validating val_loss:0.4156 val_acc:0.8670
epoch=88 train_loss:0.2157 train_acc:0.9235 validating val_loss:0.4229 val_acc:0.8670
epoch=89 train_loss:0.2120 train_acc:0.9251 validating val_loss:0.4177 val_acc:0.8679
epoch=90 train_loss:0.2129 train_acc:0.9257 validating val_loss:0.4266 val_acc:0.8668
epoch=91 train_loss:0.2099 train_acc:0.9264 validating val_loss:0.4195 val_acc:0.8672
epoch=92 train_loss:0.2085 train_acc:0.9261 validating val_loss:0.4198 val_acc:0.8682
epoch=93 train_loss:0.2050 train_acc:0.9275 validating val_loss:0.4138 val_acc:0.8677
epoch=94 train_loss:0.2033 train_acc:0.9283 validating val_loss:0.4248 val_acc:0.8656
epoch=95 train_loss:0.1995 train_acc:0.9298 validating val_loss:0.4258 val_acc:0.8698
Epoch    95: reducing learning rate of group 0 to 1.0000e-04.
epoch=96 train_loss:0.1974 train_acc:0.9312 validating val_loss:0.4177 val_acc:0.8698
epoch=97 train_loss:0.1928 train_acc:0.9312 validating val_loss:0.4181 val_acc:0.8702
epoch=98 train_loss:0.1922 train_acc:0.9326 validating val_loss:0.4177 val_acc:0.8693
epoch=99 train_loss:0.1935 train_acc:0.9319 validating val_loss:0.4154 val_acc:0.8696
epoch=100 train_loss:0.1893 train_acc:0.9344 validating val_loss:0.4173 val_acc:0.8693
epoch=101 train_loss:0.1850 train_acc:0.9338 validating val_loss:0.4173 val_acc:0.8696
epoch=102 train_loss:0.1847 train_acc:0.9337 validating val_loss:0.4167 val_acc:0.8709
epoch=103 train_loss:0.1883 train_acc:0.9331 validating val_loss:0.4166 val_acc:0.8705
epoch=104 train_loss:0.1889 train_acc:0.9333 validating val_loss:0.4166 val_acc:0.8694
epoch=105 train_loss:0.1876 train_acc:0.9330 validating val_loss:0.4195 val_acc:0.8706
epoch=106 train_loss:0.1884 train_acc:0.9333 validating val_loss:0.4194 val_acc:0.8703
Epoch   106: reducing learning rate of group 0 to 1.0000e-05.
epoch=107 train_loss:0.1861 train_acc:0.9333 validating val_loss:0.4203 val_acc:0.8705
epoch=108 train_loss:0.1835 train_acc:0.9344 validating val_loss:0.4181 val_acc:0.8700
epoch=109 train_loss:0.1874 train_acc:0.9339 validating val_loss:0.4175 val_acc:0.8703
epoch=110 train_loss:0.1850 train_acc:0.9341 validating val_loss:0.4174 val_acc:0.8706
epoch=111 train_loss:0.1880 train_acc:0.9343 validating val_loss:0.4191 val_acc:0.8701
epoch=112 train_loss:0.1872 train_acc:0.9351 validating val_loss:0.4172 val_acc:0.8699
epoch=113 train_loss:0.1882 train_acc:0.9349 validating val_loss:0.4156 val_acc:0.8699
epoch=114 train_loss:0.1896 train_acc:0.9334 validating val_loss:0.4214 val_acc:0.8699
epoch=115 train_loss:0.1851 train_acc:0.9362 validating val_loss:0.4162 val_acc:0.8695
epoch=116 train_loss:0.1848 train_acc:0.9355 validating val_loss:0.4211 val_acc:0.8707
epoch=117 train_loss:0.1827 train_acc:0.9354 validating val_loss:0.4174 val_acc:0.8695
Epoch   117: reducing learning rate of group 0 to 1.0000e-06.
epoch=118 train_loss:0.1848 train_acc:0.9356 validating val_loss:0.4198 val_acc:0.8694
epoch=119 train_loss:0.1862 train_acc:0.9342 validating val_loss:0.4202 val_acc:0.8703
epoch=120 train_loss:0.1844 train_acc:0.9337 validating val_loss:0.4181 val_acc:0.8696
epoch=121 train_loss:0.1858 train_acc:0.9353 validating val_loss:0.4188 val_acc:0.8698
epoch=122 train_loss:0.1870 train_acc:0.9338 validating val_loss:0.4188 val_acc:0.8709
epoch=123 train_loss:0.1866 train_acc:0.9329 validating val_loss:0.4164 val_acc:0.8701
epoch=124 train_loss:0.1850 train_acc:0.9351 validating val_loss:0.4180 val_acc:0.8709
epoch=125 train_loss:0.1858 train_acc:0.9350 validating val_loss:0.4182 val_acc:0.8694
epoch=126 train_loss:0.1807 train_acc:0.9369 validating val_loss:0.4159 val_acc:0.8701
epoch=127 train_loss:0.1828 train_acc:0.9360 validating val_loss:0.4190 val_acc:0.8699
epoch=128 train_loss:0.1850 train_acc:0.9348 validating val_loss:0.4177 val_acc:0.8700
Epoch   128: reducing learning rate of group 0 to 1.0000e-07.
epoch=129 train_loss:0.1841 train_acc:0.9351 validating val_loss:0.4168 val_acc:0.8702
epoch=130 train_loss:0.1846 train_acc:0.9343 validating val_loss:0.4165 val_acc:0.8697
epoch=131 train_loss:0.1860 train_acc:0.9352 validating val_loss:0.4175 val_acc:0.8701
epoch=132 train_loss:0.1828 train_acc:0.9350 validating val_loss:0.4154 val_acc:0.8708
epoch=133 train_loss:0.1849 train_acc:0.9348 validating val_loss:0.4182 val_acc:0.8691
epoch=134 train_loss:0.1837 train_acc:0.9357 validating val_loss:0.4168 val_acc:0.8693
epoch=135 train_loss:0.1841 train_acc:0.9348 validating val_loss:0.4164 val_acc:0.8704
epoch=136 train_loss:0.1860 train_acc:0.9342 validating val_loss:0.4156 val_acc:0.8701
epoch=137 train_loss:0.1854 train_acc:0.9353 validating val_loss:0.4191 val_acc:0.8702
epoch=138 train_loss:0.1819 train_acc:0.9353 validating val_loss:0.4181 val_acc:0.8709
epoch=139 train_loss:0.1869 train_acc:0.9336 validating val_loss:0.4185 val_acc:0.8707
Epoch   139: reducing learning rate of group 0 to 1.0000e-08.
epoch=140 train_loss:0.1805 train_acc:0.9358 validating val_loss:0.4155 val_acc:0.8694
epoch=141 train_loss:0.1848 train_acc:0.9353 validating val_loss:0.4164 val_acc:0.8701
epoch=142 train_loss:0.1860 train_acc:0.9348 validating val_loss:0.4173 val_acc:0.8713
epoch=143 train_loss:0.1852 train_acc:0.9349 validating val_loss:0.4157 val_acc:0.8707
epoch=144 train_loss:0.1834 train_acc:0.9362 validating val_loss:0.4181 val_acc:0.8693
epoch=145 train_loss:0.1864 train_acc:0.9332 validating val_loss:0.4166 val_acc:0.8701
epoch=146 train_loss:0.1838 train_acc:0.9360 validating val_loss:0.4188 val_acc:0.8707
epoch=147 train_loss:0.1839 train_acc:0.9360 validating val_loss:0.4153 val_acc:0.8696
epoch=148 train_loss:0.1798 train_acc:0.9357 validating val_loss:0.4201 val_acc:0.8695
epoch=149 train_loss:0.1855 train_acc:0.9345 validating val_loss:0.4174 val_acc:0.8700
epoch=150 train_loss:0.1845 train_acc:0.9339 validating val_loss:0.4159 val_acc:0.8693
epoch=151 train_loss:0.1830 train_acc:0.9348 validating val_loss:0.4193 val_acc:0.8698
epoch=152 train_loss:0.1860 train_acc:0.9338 validating val_loss:0.4168 val_acc:0.8711
epoch=153 train_loss:0.1867 train_acc:0.9348 validating val_loss:0.4163 val_acc:0.8719
epoch=154 train_loss:0.1860 train_acc:0.9344 validating val_loss:0.4171 val_acc:0.8712
epoch=155 train_loss:0.1846 train_acc:0.9346 validating val_loss:0.4180 val_acc:0.8697
epoch=156 train_loss:0.1860 train_acc:0.9351 validating val_loss:0.4153 val_acc:0.8705
epoch=157 train_loss:0.1868 train_acc:0.9346 validating val_loss:0.4152 val_acc:0.8699
epoch=158 train_loss:0.1816 train_acc:0.9376 validating val_loss:0.4212 val_acc:0.8705
epoch=159 train_loss:0.1836 train_acc:0.9345 validating val_loss:0.4181 val_acc:0.8704
epoch=160 train_loss:0.1856 train_acc:0.9340 validating val_loss:0.4153 val_acc:0.8706
epoch=161 train_loss:0.1829 train_acc:0.9341 validating val_loss:0.4177 val_acc:0.8707
epoch=162 train_loss:0.1814 train_acc:0.9351 validating val_loss:0.4163 val_acc:0.8699
epoch=163 train_loss:0.1833 train_acc:0.9347 validating val_loss:0.4206 val_acc:0.8708
epoch=164 train_loss:0.1854 train_acc:0.9348 validating val_loss:0.4168 val_acc:0.8700
epoch=165 train_loss:0.1825 train_acc:0.9352 validating val_loss:0.4159 val_acc:0.8705
epoch=166 train_loss:0.1843 train_acc:0.9339 validating val_loss:0.4190 val_acc:0.8698
epoch=167 train_loss:0.1849 train_acc:0.9349 validating val_loss:0.4174 val_acc:0.8695
epoch=168 train_loss:0.1833 train_acc:0.9353 validating val_loss:0.4178 val_acc:0.8705
epoch=169 train_loss:0.1790 train_acc:0.9359 validating val_loss:0.4206 val_acc:0.8705
epoch=170 train_loss:0.1834 train_acc:0.9342 validating val_loss:0.4224 val_acc:0.8694
epoch=171 train_loss:0.1870 train_acc:0.9334 validating val_loss:0.4212 val_acc:0.8699
epoch=172 train_loss:0.1833 train_acc:0.9353 validating val_loss:0.4198 val_acc:0.8697
epoch=173 train_loss:0.1868 train_acc:0.9341 validating val_loss:0.4165 val_acc:0.8704
epoch=174 train_loss:0.1832 train_acc:0.9357 validating val_loss:0.4190 val_acc:0.8702
epoch=175 train_loss:0.1856 train_acc:0.9337 validating val_loss:0.4169 val_acc:0.8710
epoch=176 train_loss:0.1849 train_acc:0.9356 validating val_loss:0.4180 val_acc:0.8716
epoch=177 train_loss:0.1824 train_acc:0.9345 validating val_loss:0.4195 val_acc:0.8698
epoch=178 train_loss:0.1844 train_acc:0.9357 validating val_loss:0.4208 val_acc:0.8706
epoch=179 train_loss:0.1844 train_acc:0.9349 validating val_loss:0.4165 val_acc:0.8699
epoch=180 train_loss:0.1860 train_acc:0.9347 validating val_loss:0.4160 val_acc:0.8713
epoch=181 train_loss:0.1845 train_acc:0.9351 validating val_loss:0.4169 val_acc:0.8692
epoch=182 train_loss:0.1877 train_acc:0.9332 validating val_loss:0.4189 val_acc:0.8710
epoch=183 train_loss:0.1856 train_acc:0.9346 validating val_loss:0.4176 val_acc:0.8699
epoch=184 train_loss:0.1848 train_acc:0.9349 validating val_loss:0.4166 val_acc:0.8713
epoch=185 train_loss:0.1841 train_acc:0.9341 validating val_loss:0.4180 val_acc:0.8707
epoch=186 train_loss:0.1869 train_acc:0.9341 validating val_loss:0.4195 val_acc:0.8696
epoch=187 train_loss:0.1849 train_acc:0.9334 validating val_loss:0.4187 val_acc:0.8697
epoch=188 train_loss:0.1838 train_acc:0.9345 validating val_loss:0.4169 val_acc:0.8690
epoch=189 train_loss:0.1824 train_acc:0.9361 validating val_loss:0.4182 val_acc:0.8709
epoch=190 train_loss:0.1858 train_acc:0.9347 validating val_loss:0.4193 val_acc:0.8695
epoch=191 train_loss:0.1817 train_acc:0.9348 validating val_loss:0.4226 val_acc:0.8704
epoch=192 train_loss:0.1820 train_acc:0.9360 validating val_loss:0.4192 val_acc:0.8707
epoch=193 train_loss:0.1836 train_acc:0.9353 validating val_loss:0.4176 val_acc:0.8708
epoch=194 train_loss:0.1845 train_acc:0.9341 validating val_loss:0.4199 val_acc:0.8701
epoch=195 train_loss:0.1824 train_acc:0.9360 validating val_loss:0.4184 val_acc:0.8700
epoch=196 train_loss:0.1834 train_acc:0.9355 validating val_loss:0.4206 val_acc:0.8710
epoch=197 train_loss:0.1854 train_acc:0.9343 validating val_loss:0.4172 val_acc:0.8709
epoch=198 train_loss:0.1839 train_acc:0.9351 validating val_loss:0.4208 val_acc:0.8705
epoch=199 train_loss:0.1833 train_acc:0.9341 validating val_loss:0.4214 val_acc:0.8700
Finished Training
